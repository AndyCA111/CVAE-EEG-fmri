{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3817,"status":"ok","timestamp":1701760930529,"user":{"displayName":"Jiaqi Wu","userId":"00803091932349494936"},"user_tz":480},"id":"3M7eve_oEtS4","outputId":"7e76a7f0-30ae-4d52-8611-433d1ab9419c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["%cd \"/content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BUOWNfRv-Efw","executionInfo":{"status":"ok","timestamp":1701760931332,"user_tz":480,"elapsed":1,"user":{"displayName":"Jiaqi Wu","userId":"00803091932349494936"}},"outputId":"bf198957-096c-4aec-e5f4-00f6f0caf9de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1z_ln8fPatUI4267ZmBksH4kCb2zS8RqM/EEG_GAN/datasets/datasets/ds002338\n"]}]},{"cell_type":"code","source":["!pip install mne\n","!pip install nibabel\n","!pip install nilearn\n","!pip install tensorflow==2.9.0\n","!pip install mne==0.23.4\n","!pip install nilearn==0.7.0\n","!pip install matplotlib==3.5.3\n","!pip install tensorflow-probability==0.12.2\n","!pip install tensorflow-determinism==0.3.0\n","!pip install tensorflow-addons==0.19.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"CdynWT-3dllo","executionInfo":{"status":"ok","timestamp":1701743344595,"user_tz":480,"elapsed":111419,"user":{"displayName":"Jiaqi Wu","userId":"00803091932349494936"}},"outputId":"cca09177-9b99-4fae-fa8f-1f3ca574b76d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mne\n","  Downloading mne-1.6.0-py3-none-any.whl (8.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from mne) (1.23.5)\n","Requirement already satisfied: scipy>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from mne) (1.11.4)\n","Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.1)\n","Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.8.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (23.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.2)\n","Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne) (0.3)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from mne) (0.7.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (4.45.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (2.8.2)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (4.0.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.31.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->mne) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2023.11.17)\n","Installing collected packages: mne\n","Successfully installed mne-1.6.0\n","Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (4.0.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from nibabel) (1.23.5)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from nibabel) (23.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel) (67.7.2)\n","Collecting nilearn\n","  Downloading nilearn-0.10.2-py3-none-any.whl (10.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.3.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nilearn) (4.9.3)\n","Requirement already satisfied: nibabel>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (4.0.2)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nilearn) (23.2)\n","Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.5.3)\n","Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (2.31.0)\n","Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.2.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.11.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel>=3.2.0->nilearn) (67.7.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->nilearn) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->nilearn) (2023.3.post1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (2023.11.17)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->nilearn) (3.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.1.5->nilearn) (1.16.0)\n","Installing collected packages: nilearn\n","Successfully installed nilearn-0.10.2\n","Collecting tensorflow==2.9.0\n","  Downloading tensorflow-2.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.7/511.7 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (1.6.3)\n","Collecting flatbuffers<2,>=1.12 (from tensorflow==2.9.0)\n","  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n","Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.9.0)\n","  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (1.59.3)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (3.9.0)\n","Collecting keras<2.10.0,>=2.9.0rc0 (from tensorflow==2.9.0)\n","  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras-preprocessing>=1.1.1 (from tensorflow==2.9.0)\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (16.0.6)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (23.2)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (1.16.0)\n","Collecting tensorboard<2.10,>=2.9 (from tensorflow==2.9.0)\n","  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (0.34.0)\n","Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0 (from tensorflow==2.9.0)\n","  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (4.5.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (1.14.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.9.0) (0.42.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2.17.3)\n","Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.10,>=2.9->tensorflow==2.9.0)\n","  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (3.5.1)\n","Collecting protobuf>=3.9.2 (from tensorflow==2.9.0)\n","  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2.31.0)\n","Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.10,>=2.9->tensorflow==2.9.0)\n","  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.10,>=2.9->tensorflow==2.9.0)\n","  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (3.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2023.11.17)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (3.2.2)\n","Installing collected packages: tensorboard-plugin-wit, keras, flatbuffers, tensorflow-estimator, tensorboard-data-server, protobuf, keras-preprocessing, gast, google-auth-oauthlib, tensorboard, tensorflow\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.14.0\n","    Uninstalling keras-2.14.0:\n","      Successfully uninstalled keras-2.14.0\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 23.5.26\n","    Uninstalling flatbuffers-23.5.26:\n","      Successfully uninstalled flatbuffers-23.5.26\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.14.0\n","    Uninstalling tensorflow-estimator-2.14.0:\n","      Successfully uninstalled tensorflow-estimator-2.14.0\n","  Attempting uninstall: tensorboard-data-server\n","    Found existing installation: tensorboard-data-server 0.7.2\n","    Uninstalling tensorboard-data-server-0.7.2:\n","      Successfully uninstalled tensorboard-data-server-0.7.2\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.3\n","    Uninstalling protobuf-3.20.3:\n","      Successfully uninstalled protobuf-3.20.3\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.5.4\n","    Uninstalling gast-0.5.4:\n","      Successfully uninstalled gast-0.5.4\n","  Attempting uninstall: google-auth-oauthlib\n","    Found existing installation: google-auth-oauthlib 1.0.0\n","    Uninstalling google-auth-oauthlib-1.0.0:\n","      Successfully uninstalled google-auth-oauthlib-1.0.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.14.1\n","    Uninstalling tensorboard-2.14.1:\n","      Successfully uninstalled tensorboard-2.14.1\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.14.0\n","    Uninstalling tensorflow-2.14.0:\n","      Successfully uninstalled tensorflow-2.14.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-datasets 4.9.3 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n","tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed flatbuffers-1.12 gast-0.4.0 google-auth-oauthlib-0.4.6 keras-2.9.0 keras-preprocessing-1.1.2 protobuf-3.19.6 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.0 tensorflow-estimator-2.9.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting mne==0.23.4\n","  Downloading mne-0.23.4-py3-none-any.whl (6.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from mne==0.23.4) (1.23.5)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from mne==0.23.4) (1.11.4)\n","Installing collected packages: mne\n","  Attempting uninstall: mne\n","    Found existing installation: mne 1.6.0\n","    Uninstalling mne-1.6.0:\n","      Successfully uninstalled mne-1.6.0\n","Successfully installed mne-0.23.4\n","Collecting nilearn==0.7.0\n","  Downloading nilearn-0.7.0-py3-none-any.whl (3.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.10/dist-packages (from nilearn==0.7.0) (1.3.2)\n","Requirement already satisfied: nibabel>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from nilearn==0.7.0) (4.0.2)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.10/dist-packages (from nilearn==0.7.0) (1.23.5)\n","Requirement already satisfied: pandas>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from nilearn==0.7.0) (1.5.3)\n","Requirement already satisfied: requests>=2 in /usr/local/lib/python3.10/dist-packages (from nilearn==0.7.0) (2.31.0)\n","Requirement already satisfied: scikit-learn>=0.19 in /usr/local/lib/python3.10/dist-packages (from nilearn==0.7.0) (1.2.2)\n","Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.10/dist-packages (from nilearn==0.7.0) (1.11.4)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from nibabel>=2.0.2->nilearn==0.7.0) (23.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel>=2.0.2->nilearn==0.7.0) (67.7.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18.0->nilearn==0.7.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18.0->nilearn==0.7.0) (2023.3.post1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2->nilearn==0.7.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2->nilearn==0.7.0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2->nilearn==0.7.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2->nilearn==0.7.0) (2023.11.17)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19->nilearn==0.7.0) (3.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.18.0->nilearn==0.7.0) (1.16.0)\n","Installing collected packages: nilearn\n","  Attempting uninstall: nilearn\n","    Found existing installation: nilearn 0.10.2\n","    Uninstalling nilearn-0.10.2:\n","      Successfully uninstalled nilearn-0.10.2\n","Successfully installed nilearn-0.7.0\n","Collecting matplotlib==3.5.3\n","  Downloading matplotlib-3.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3) (4.45.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3) (1.4.5)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.3) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.5.3) (1.16.0)\n","Installing collected packages: matplotlib\n","  Attempting uninstall: matplotlib\n","    Found existing installation: matplotlib 3.7.1\n","    Uninstalling matplotlib-3.7.1:\n","      Successfully uninstalled matplotlib-3.7.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires fastapi, which is not installed.\n","lida 0.0.10 requires kaleido, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\n","plotnine 0.12.4 requires matplotlib>=3.6.0, but you have matplotlib 3.5.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed matplotlib-3.5.3\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["matplotlib","mpl_toolkits"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting tensorflow-probability==0.12.2\n","  Downloading tensorflow_probability-0.12.2-py2.py3-none-any.whl (4.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability==0.12.2) (1.16.0)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability==0.12.2) (1.23.5)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability==0.12.2) (4.4.2)\n","Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability==0.12.2) (2.2.1)\n","Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability==0.12.2) (0.4.0)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability==0.12.2) (0.1.8)\n","Installing collected packages: tensorflow-probability\n","  Attempting uninstall: tensorflow-probability\n","    Found existing installation: tensorflow-probability 0.22.0\n","    Uninstalling tensorflow-probability-0.22.0:\n","      Successfully uninstalled tensorflow-probability-0.22.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","dopamine-rl 4.0.6 requires tensorflow-probability>=0.13.0, but you have tensorflow-probability 0.12.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed tensorflow-probability-0.12.2\n","Collecting tensorflow-determinism==0.3.0\n","  Downloading tensorflow-determinism-0.3.0.tar.gz (12 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: tensorflow-determinism\n","  Building wheel for tensorflow-determinism (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tensorflow-determinism: filename=tensorflow_determinism-0.3.0-py3-none-any.whl size=9139 sha256=e75cd9894fce255358753616c2bc39b4eeb766a3a5da226770bb9e0ee50cd8b3\n","  Stored in directory: /root/.cache/pip/wheels/ed/09/84/9e43798c7534d6fcd18416933d8762c8d74ec59cd914a8644b\n","Successfully built tensorflow-determinism\n","Installing collected packages: tensorflow-determinism\n","Successfully installed tensorflow-determinism-0.3.0\n","Collecting tensorflow-addons==0.19.0\n","  Downloading tensorflow_addons-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons==0.19.0) (23.2)\n","Collecting typeguard>=2.7 (from tensorflow-addons==0.19.0)\n","  Downloading typeguard-4.1.5-py3-none-any.whl (34 kB)\n","Collecting typing-extensions>=4.7.0 (from typeguard>=2.7->tensorflow-addons==0.19.0)\n","  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n","Installing collected packages: typing-extensions, typeguard, tensorflow-addons\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.5.0\n","    Uninstalling typing_extensions-4.5.0:\n","      Successfully uninstalled typing_extensions-4.5.0\n","Successfully installed tensorflow-addons-0.19.0 typeguard-4.1.5 typing-extensions-4.8.0\n"]}]},{"cell_type":"markdown","source":["# Data Visualization"],"metadata":{"id":"Tu-VdRciBQcx"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"nuyEb13tGM4J"},"outputs":[],"source":["\n","import tensorflow as tf\n","\n","import tensorflow_probability as tfp\n","\n","import numpy as np\n","\n","\n","\n","class DCT3D(tf.keras.layers.Layer):\n","\t\"\"\"\n","\tDCT3D - real Discrete Cosine Transform\n","\n","\tPerforms the discrete cosine transform\n","\n","\tExample usage:\n","\t>>> import numpy as np\n","\t>>> import tensorflow as tf\n","\t>>> import tensorflow_probability as tfp\n","\t>>>\n","\t>>> x = tf.constant(np.expand_dims(np.random.rand(16,10),axis=-1), dtype=tf.float32)\n","\t>>> N = x.shape[1]\n","\t>>> irdft = irDFT(N, out=N*2)\n","\t>>> irdft(x)\n","\t\"\"\"\n","\n","\tdef __init__(self, N_1, N_2, N_3, **kwargs):\n","\n","\t\tself.N_1=N_1\n","\t\tself.N_2=N_2\n","\t\tself.N_3=N_3\n","\n","\t\tsuper(DCT3D, self).__init__(**kwargs)\n","\n","\tdef build(self, input_shape):\n","\n","\t\tn1 = np.arange(self.N_1)\n","\t\tk1 = n1.reshape((self.N_1,1))\n","\t\tn2 = np.arange(self.N_2)\n","\t\tk2 = n2.reshape((self.N_2,1))\n","\t\tn3 = np.arange(self.N_3)\n","\t\tk3 = n3.reshape((self.N_3,1))\n","\n","\t\t#variable initializer\n","\t\tself.n1 = self.add_weight('n1',\n","\t\t\t\t\t\t\t\tshape=[n1.shape[0]],\n","\t\t\t\t\t\t\t\tinitializer=tf.constant_initializer(n1),\n","\t\t\t\t\t\t\t\tdtype=tf.float32,\n","\t\t\t\t\t\t\t\ttrainable=False)\n","\t\tself.k1 = self.add_weight('k1',\n","\t\t\t\t\t\t\t\tshape=[k1.shape[0], k1.shape[1]],\n","\t\t\t\t\t\t\t\tinitializer=tf.constant_initializer(k1),\n","\t\t\t\t\t\t\t\tdtype=tf.float32,\n","\t\t\t\t\t\t\t\ttrainable=False)\n","\t\tself.n2 = self.add_weight('n2',\n","\t\t\t\t\t\t\t\tshape=[n2.shape[0]],\n","\t\t\t\t\t\t\t\tinitializer=tf.constant_initializer(n2),\n","\t\t\t\t\t\t\t\tdtype=tf.float32,\n","\t\t\t\t\t\t\t\ttrainable=False)\n","\t\tself.k2 = self.add_weight('k2',\n","\t\t\t\t\t\t\t\tshape=[k2.shape[0], k2.shape[1]],\n","\t\t\t\t\t\t\t\tinitializer=tf.constant_initializer(k2),\n","\t\t\t\t\t\t\t\tdtype=tf.float32,\n","\t\t\t\t\t\t\t\ttrainable=False)\n","\t\tself.n3 = self.add_weight('n3',\n","\t\t\t\t\t\t\t\tshape=[n3.shape[0]],\n","\t\t\t\t\t\t\t\tinitializer=tf.constant_initializer(n3),\n","\t\t\t\t\t\t\t\tdtype=tf.float32,\n","\t\t\t\t\t\t\t\ttrainable=False)\n","\t\tself.k3 = self.add_weight('k3',\n","\t\t\t\t\t\t\t\tshape=[k3.shape[0], k3.shape[1]],\n","\t\t\t\t\t\t\t\tinitializer=tf.constant_initializer(k3),\n","\t\t\t\t\t\t\t\tdtype=tf.float32,\n","\t\t\t\t\t\t\t\ttrainable=False)\n","\n","\t\tself.N1 = self.add_weight('N1',\n","\t\t\t\t\t\t\t\tshape=[1],\n","\t\t\t\t\t\t\t\tinitializer=tf.constant_initializer(self.N_1),\n","\t\t\t\t\t\t\t\tdtype=tf.float32,\n","\t\t\t\t\t\t\t\ttrainable=False)\n","\t\tself.N2 = self.add_weight('N2',\n","\t\t\t\t\t\t\t\tshape=[1],\n","\t\t\t\t\t\t\t\tinitializer=tf.constant_initializer(self.N_2),\n","\t\t\t\t\t\t\t\tdtype=tf.float32,\n","\t\t\t\t\t\t\t\ttrainable=False)\n","\t\tself.N3 = self.add_weight('N3',\n","\t\t\t\t\t\t\t\tshape=[1],\n","\t\t\t\t\t\t\t\tinitializer=tf.constant_initializer(self.N_3),\n","\t\t\t\t\t\t\t\tdtype=tf.float32,\n","\t\t\t\t\t\t\t\ttrainable=False)\n","\n","\tdef call(self, x):\n","\t\tz3 = 2*tf.tensordot((tf.cos(np.pi*(2*self.n3+1)*self.k3/(2*self.N3))), x, axes=[[1], [3]])\n","\t\tz3 = tf.transpose(z3, [1,2,3,0])\n","\n","\t\tz2 = 2*tf.tensordot((tf.cos(np.pi*(2*self.n2+1)*self.k2/(2*self.N2))), z3, axes=[[1], [2]])\n","\t\tz2 = tf.transpose(z2, [1,2,0,3])\n","\n","\t\tz1 = 2*tf.tensordot((tf.cos(np.pi*(2*self.n1+1)*self.k1/(2*self.N1))), z2, axes=[[1], [1]])\n","\t\tz1 = tf.transpose(z1, [1,0,2,3])\n","\t\treturn z1\n","\n","\tdef get_config(self):\n","\t\treturn {\n","\t\t\t'N_1': self.N_1,\n","\t\t\t'N_2': self.N_2,\n","\t\t\t'N_3': self.N_3,\n","\t\t}\n","\n","\t@classmethod\n","\tdef from_config(cls, config):\n","\t\treturn cls(**config)\n","\n","\n","class iDCT3D(tf.keras.layers.Layer):\n","\t\"\"\"\n","\tDCT3D - real Discrete Cosine Transform\n","\n","\tPerforms the discrete cosine transform\n","\n","\tExample usage:\n","\t>>> import numpy as np\n","\t>>> import tensorflow as tf\n","\t>>> import tensorflow_probability as tfp\n","\t>>>\n","\t>>> x = tf.constant(np.expand_dims(np.random.rand(16,10),axis=-1), dtype=tf.float32)\n","\t>>> N = x.shape[1]\n","\t>>> irdft = irDFT(N, out=N*2)\n","\t>>> irdft(x)\n","\t\"\"\"\n","\n","\tdef __init__(self, N_1, N_2, N_3, **kwargs):\n","\n","\t\tself.N_1=N_1\n","\t\tself.N_2=N_2\n","\t\tself.N_3=N_3\n","\n","\t\tsuper(iDCT3D, self).__init__(**kwargs)\n","\n","\tdef build(self, input_shape):\n","\n","\t\tn1 = np.arange(self.N_1)\n","\t\tk1 = n1.reshape((self.N_1,1))\n","\t\tn2 = np.arange(self.N_2)\n","\t\tk2 = n2.reshape((self.N_2,1))\n","\t\tn3 = np.arange(self.N_3)\n","\t\tk3 = n3.reshape((self.N_3,1))\n","\n","\t\t#variable initializer\n","\t\tself.n1 = self.add_weight('n1',\n","\t\t\t\t\t\t\t\tshape=[n1.shape[0]],\n","\t\t\t\t\t\t\t\tinitializer=tf.constant_initializer(n1),\n","\t\t\t\t\t\t\t\tdtype=tf.float32,\n","\t\t\t\t\t\t\t\ttrainable=False)\n","\t\tself.k1 = self.add_weight('k1',\n","\t\t\t\t\t\t\t\tshape=[k1.shape[0], k1.shape[1]],\n","\t\t\t\t\t\t\t\tinitializer=tf.constant_initializer(k1),\n","\t\t\t\t\t\t\t\tdtype=tf.float32,\n","\t\t\t\t\t\t\t\ttrainable=False)\n","\t\tself.n2 = self.add_weight('n2',\n","\t\t\t\t\t\t\t\tshape=[n2.shape[0]],\n","\t\t\t\t\t\t\t\tinitializer=tf.constant_initializer(n2),\n","\t\t\t\t\t\t\t\tdtype=tf.float32,\n","\t\t\t\t\t\t\t\ttrainable=False)\n","\t\tself.k2 = self.add_weight('k2',\n","\t\t\t\t\t\t\t\tshape=[k2.shape[0], k2.shape[1]],\n","\t\t\t\t\t\t\t\tinitializer=tf.constant_initializer(k2),\n","\t\t\t\t\t\t\t\tdtype=tf.float32,\n","\t\t\t\t\t\t\t\ttrainable=False)\n","\t\tself.n3 = self.add_weight('n3',\n","\t\t\t\t\t\t\t\tshape=[n3.shape[0]],\n","\t\t\t\t\t\t\t\tinitializer=tf.constant_initializer(n3),\n","\t\t\t\t\t\t\t\tdtype=tf.float32,\n","\t\t\t\t\t\t\t\ttrainable=False)\n","\t\tself.k3 = self.add_weight('k3',\n","\t\t\t\t\t\t\t\tshape=[k3.shape[0], k3.shape[1]],\n","\t\t\t\t\t\t\t\tinitializer=tf.constant_initializer(k3),\n","\t\t\t\t\t\t\t\tdtype=tf.float32,\n","\t\t\t\t\t\t\t\ttrainable=False)\n","\n","\t\tself.N1 = self.add_weight('N1',\n","\t\t\t\t\t\t\t\tshape=[1],\n","\t\t\t\t\t\t\t\tinitializer=tf.constant_initializer(self.N_1),\n","\t\t\t\t\t\t\t\tdtype=tf.float32,\n","\t\t\t\t\t\t\t\ttrainable=False)\n","\t\tself.N2 = self.add_weight('N2',\n","\t\t\t\t\t\t\t\tshape=[1],\n","\t\t\t\t\t\t\t\tinitializer=tf.constant_initializer(self.N_2),\n","\t\t\t\t\t\t\t\tdtype=tf.float32,\n","\t\t\t\t\t\t\t\ttrainable=False)\n","\t\tself.N3 = self.add_weight('N3',\n","\t\t\t\t\t\t\t\tshape=[1],\n","\t\t\t\t\t\t\t\tinitializer=tf.constant_initializer(self.N_3),\n","\t\t\t\t\t\t\t\tdtype=tf.float32,\n","\t\t\t\t\t\t\t\ttrainable=False)\n","\n","\t\t#remove this\n","\t\tnorm3 = np.ones((self.N_1,self.N_2,self.N_3))\n","\t\tnorm3[:,:,1:] = 2\n","\t\tnorm2 = np.ones((self.N_1,self.N_2,self.N_3))\n","\t\tnorm2[:,1:,:] = 2\n","\t\tnorm1 = np.ones((self.N_1,self.N_2,self.N_3))\n","\t\tnorm1[1:,:,:] = 2\n","\n","\t\tself.norm1 = self.add_weight('norm1',\n","\t\t\t\t\t\t\t\tshape=[self.N_1,self.N_2,self.N_3],\n","\t\t\t\t\t\t\t\tinitializer=tf.constant_initializer(norm1),\n","\t\t\t\t\t\t\t\tdtype=tf.float32,\n","\t\t\t\t\t\t\t\ttrainable=False)\n","\t\tself.norm2 = self.add_weight('norm2',\n","\t\t\t\t\t\t\t\tshape=[self.N_1,self.N_2,self.N_3],\n","\t\t\t\t\t\t\t\tinitializer=tf.constant_initializer(norm2),\n","\t\t\t\t\t\t\t\tdtype=tf.float32,\n","\t\t\t\t\t\t\t\ttrainable=False)\n","\t\tself.norm3 = self.add_weight('norm3',\n","\t\t\t\t\t\t\t\tshape=[self.N_1,self.N_2,self.N_3],\n","\t\t\t\t\t\t\t\tinitializer=tf.constant_initializer(norm3),\n","\t\t\t\t\t\t\t\tdtype=tf.float32,\n","\t\t\t\t\t\t\t\ttrainable=False)\n","\n","\tdef call(self, x):\n","\t\tz3 = (1/(2*self.N3))*tf.tensordot((tf.cos(np.pi*self.n3*(2*self.k3+1)/(2*self.N3))), x*self.norm3,\n","\t\t\t\t\t\t\t\t\t\t  axes=[[1], [3]])\n","\t\tz3 = tf.transpose(z3, [1,2,3,0])\n","\n","\t\tz2 = (1/(2*self.N2))*tf.tensordot((tf.cos(np.pi*self.n2*(2*self.k2+1)/(2*self.N2))), z3*self.norm2,\n","\t\t\t\t\t\t\t\t\t\t  axes=[[1], [2]])\n","\t\tz2= tf.transpose(z2, [1,2,0,3])\n","\n","\t\tz1 = (1/(2*self.N1))*tf.tensordot((tf.cos(np.pi*self.n1*(2*self.k1+1)/(2*self.N1))), z2*self.norm1,\n","\t\t\t\t\t\t\t\t\t\t  axes=[[1], [1]])\n","\n","\t\treturn tf.transpose(z1, [1,0,2,3])\n","\n","\tdef get_config(self):\n","\t\treturn {\n","\t\t\t'N_1': self.N_1,\n","\t\t\t'N_2': self.N_2,\n","\t\t\t'N_3': self.N_3,\n","\t\t}\n","\n","\t@classmethod\n","\tdef from_config(cls, config):\n","\t\treturn cls(**config)\n","\n","\n","\n","class padded_iDCT3D(tf.keras.layers.Layer):\n","\t\"\"\"\n","\tDCT3D - real Discrete Cosine Transform\n","\n","\tPerforms the discrete cosine transform\n","\n","\tExample usage:\n","\t>>> import numpy as np\n","\t>>> import tensorflow as tf\n","\t>>> import tensorflow_probability as tfp\n","\t>>>\n","\t>>> x = tf.constant(np.expand_dims(np.random.rand(16,10),axis=-1), dtype=tf.float32)\n","\t>>> N = x.shape[1]\n","\t>>> irdft = irDFT(N, out=N*2)\n","\t>>> irdft(x)\n","\t\"\"\"\n","\n","\tdef __init__(self, in1, in2, in3, out1, out2, out3, **kwargs):\n","\n","\t\tassert out1 is not None\n","\t\tassert out3 is not None\n","\t\tassert out3 is not None\n","\n","\t\tself.in1 = in1\n","\t\tself.in2 = in2\n","\t\tself.in3 = in3\n","\n","\t\tself.out1 = out1\n","\t\tself.out2 = out2\n","\t\tself.out3 = out3\n","\n","\t\tsuper(padded_iDCT3D, self).__init__(**kwargs)\n","\n","\n","\tdef build(self, input_shape):\n","\n","\t\tself.idct3 = iDCT3D(self.out1, self.out2, self.out3)\n","\n","\tdef call(self, x):\n","\n","\t\tpaddings = [[0,0],\n","\t\t\t\t\t[0, self.out1-self.in1],\n","\t\t\t\t   [0, self.out2-self.in2],\n","\t\t\t\t   [0, self.out3-self.in3]]\n","\n","\t\treturn self.idct3(tf.pad(x, paddings))\n","\n","\tdef get_config(self):\n","\t\treturn {\n","\t\t\t\"in1\": self.in1,\n","\t\t\t\"in2\": self.in2,\n","\t\t\t\"in3\": self.in3,\n","\t\t\t\"out1\": self.out1,\n","\t\t\t\"out2\": self.out2,\n","\t\t\t\"out3\": self.out3,\n","\t\t}\n","\n","\t@classmethod\n","\tdef from_config(cls, config):\n","\t\treturn cls(**config)\n","\n","\n","\n","class variational_iDCT3D(tf.keras.layers.Layer):\n","\t\"\"\"\n","\tDCT3D - real Discrete Cosine Transform\n","\n","\tPerforms the discrete cosine transform\n","\n","\tExample usage:\n","\t>>> import numpy as np\n","\t>>> import tensorflow as tf\n","\t>>> import tensorflow_probability as tfp\n","\t>>>\n","\t>>> x = tf.constant(np.expand_dims(np.random.rand(16,10),axis=-1), dtype=tf.float32)\n","\t>>> N = x.shape[1]\n","\t>>> irdft = irDFT(N, out=N*2)\n","\t>>> irdft(x)\n","\t\"\"\"\n","\n","\tdef __init__(self, in1, in2, in3, out1, out2, out3, rand1, rand2, rand3, coefs_perturb=True, dependent=False, posterior_dimension=1, distribution=None, random_padding=False, normal_loc_initializer=None, normal_scale_initializer=None, w1_initializer=None, w2_initializer=None, w3_initializer=None, loc_posterior_initializer=None, scale_posterior_initializer=None, biases_initializer=None, trainable=True, **kwargs):\n","\t\t\"\"\"\n","\t\tin1 - int - first dimension input\n","\n","\t\tIf Gamma is used please cite arXiv:1805.08498 - Figurnov et al. 2019\n","\n","\n","\t\tdistribution variances\n","\t\t\"\"\"\n","\n","\t\tassert out1 is not None\n","\t\tassert out3 is not None\n","\t\tassert out3 is not None\n","\n","\n","\t\tassert (not dependent and posterior_dimension == 1) or dependent\n","\n","\t\tself.in1 = in1\n","\t\tself.in2 = in2\n","\t\tself.in3 = in3\n","\t\tself.out1 = out1\n","\t\tself.out2 = out2\n","\t\tself.out3 = out3\n","\t\tself.rand1 = rand1\n","\t\tself.rand2 = rand2\n","\t\tself.rand3 = rand3\n","\t\tself.coefs_perturb = coefs_perturb\n","\t\tself.dependent = dependent\n","\t\tself.posterior_dimension = posterior_dimension\n","\t\tself.distribution = distribution\n","\t\tself.random_padding = random_padding\n","\t\tself.normal_loc_initializer=normal_loc_initializer\n","\t\tself.normal_scale_initializer=normal_scale_initializer\n","\t\tself.w1_initializer=w1_initializer\n","\t\tself.w2_initializer=w2_initializer\n","\t\tself.w3_initializer=w3_initializer\n","\t\tself.loc_posterior_initializer=loc_posterior_initializer\n","\t\tself.scale_posterior_initializer=scale_posterior_initializer\n","\t\tself.biases_initializer=biases_initializer\n","\t\tself.trainable=trainable\n","\n","\t\tsuper(variational_iDCT3D, self).__init__(**kwargs)\n","\n","\tdef build(self, input_shape):\n","\n","\t\tif(self.distribution is None):\n","\t\t\tself.distribution=\"Normal\"#default\n","\n","\t\t#process initializers\n","\t\tif(self.normal_loc_initializer==None):#default initializers\n","\t\t\tself.normal_loc_initializer=tf.initializers.random_normal(stddev=0.1)\n","\t\tif(self.normal_scale_initializer==None):\n","\t\t\tself.normal_scale_initializer=tf.initializers.random_normal(mean=-3., stddev=0.1)\n","\t\tif(self.loc_posterior_initializer==None):\n","\t\t\tself.loc_posterior_initializer=tf.initializers.GlorotUniform()\n","\t\tif(self.scale_posterior_initializer==None):\n","\t\t\tself.scale_posterior_initializer=tf.initializers.Ones()\n","\t\tif(self.biases_initializer==None):\n","\t\t\tself.biases_initializer=tf.initializers.Ones()\n","\t\tif(self.w1_initializer==None):\n","\t\t\tself.w1_initializer=tf.initializers.GlorotUniform()\n","\t\tif(self.w2_initializer==None):\n","\t\t\tself.w2_initializer=tf.initializers.GlorotUniform()\n","\t\tif(self.w3_initializer==None):\n","\t\t\tself.w3_initializer=tf.initializers.GlorotUniform()\n","\n","\t\tconstraint=tf.keras.constraints.NonNeg()\n","\n","\t\tif(self.coefs_perturb):\n","\t\t\tself.normal= tfp.layers.default_mean_field_normal_fn(loc_constraint=constraint, loc_initializer=self.normal_loc_initializer, untransformed_scale_initializer=self.normal_scale_initializer)(tf.float32, [self.in1, self.in2, self.in3], 'normal_posterior', self.trainable, self.add_weight)\n","\t\tif(self.dependent):\n","\t\t\tself.w1 = self.add_weight('W1',\n","\t\t\t\t\t\t\t\tshape=[self.in1*self.in2*self.in3, self.posterior_dimension],\n","\t\t\t\t\t\t\t\tinitializer=self.w1_initializer,\n","\t\t\t\t\t\t\t\tdtype=tf.float32,\n","\t\t\t\t\t\t\t\ttrainable=self.trainable)\n","\t\t\tself.w2 = self.add_weight('W2',\n","\t\t\t\t\t\t\t\tshape=[self.in1*self.in2*self.in3, self.posterior_dimension],\n","\t\t\t\t\t\t\t\tinitializer=self.w2_initializer,\n","\t\t\t\t\t\t\t\tdtype=tf.float32,\n","\t\t\t\t\t\t\t\ttrainable=self.trainable)\n","\t\t\tself.w3 = self.add_weight('W3',\n","\t\t\t\t\t\t\t\tshape=[self.in1*self.in2*self.in3, self.posterior_dimension],\n","\t\t\t\t\t\t\t\tinitializer=self.w3_initializer,\n","\t\t\t\t\t\t\t\tdtype=tf.float32,\n","\t\t\t\t\t\t\t\ttrainable=self.trainable)\n","\n","\t\tself.padded_idct3 = padded_iDCT3D(self.in1+self.rand1, self.in2+self.rand2, self.in3+self.rand3, self.out1, self.out2, self.out3)\n","\n","\t\tself.shape_normal1 = (self.rand1, self.in2, self.in3)\n","\t\tself.shape_normal2 = (self.in1+self.rand1, self.rand2, self.in3)\n","\t\tself.shape_normal3 = (self.in1+self.rand1, self.in2+self.rand2, self.rand3)\n","\n","\t\tif(self.distribution in [\"Normal\", \"VonMises\"]):\n","\t\t\tself.loc = self.add_weight('loc_posterior',\n","\t\t\t\t\t\t\t\t\t\tshape=[self.posterior_dimension, self.shape_normal1[0]*self.shape_normal1[1]*self.shape_normal1[2]+self.shape_normal2[0]*self.shape_normal2[1]*self.shape_normal2[2]+self.shape_normal3[0]*self.shape_normal3[1]*self.shape_normal3[2]],\n","\t\t\t\t\t\t\t\t\t\tinitializer=self.loc_posterior_initializer,\n","\t\t\t\t\t\t\t\t\t\tconstraint=None,\n","\t\t\t\t\t\t\t\t\t\tdtype=tf.float32,\n","\t\t\t\t\t\t\t\t\t\ttrainable=self.trainable)\n","\t\t\tself.scale = self.add_weight('scale_posterior',\n","\t\t\t\t\t\t\t\t\t\tshape=[self.posterior_dimension, self.shape_normal1[0]*self.shape_normal1[1]*self.shape_normal1[2]+self.shape_normal2[0]*self.shape_normal2[1]*self.shape_normal2[2]+self.shape_normal3[0]*self.shape_normal3[1]*self.shape_normal3[2]],\n","\t\t\t\t\t\t\t\t\t\tinitializer=self.scale_posterior_initializer,\n","\t\t\t\t\t\t\t\t\t\tconstraint=constraint,\n","\t\t\t\t\t\t\t\t\t\tdtype=tf.float32,\n","\t\t\t\t\t\t\t\t\t\ttrainable=self.trainable)\n","\t\t\tself.biases = self.add_weight('biases',\n","\t\t\t\t\t\t\t\t\t\tshape=[self.posterior_dimension, self.shape_normal1[0]*self.shape_normal1[1]*self.shape_normal1[2]+self.shape_normal2[0]*self.shape_normal2[1]*self.shape_normal2[2]+self.shape_normal3[0]*self.shape_normal3[1]*self.shape_normal3[2]],\n","\t\t\t\t\t\t\t\t\t\tinitializer=self.biases_initializer,\n","\t\t\t\t\t\t\t\t\t\tconstraint=None,\n","\t\t\t\t\t\t\t\t\t\tdtype=tf.float32,\n","\t\t\t\t\t\t\t\t\t\ttrainable=self.trainable)\n","\n","\t\tif(self.random_padding):\n","\t\t\tself.random_pad1 = RandomizeFrequencies(self.in1, self.in1+self.rand1, dim=1)\n","\t\t\tself.random_pad2 = RandomizeFrequencies(self.in2, self.in2+self.rand2, dim=2)\n","\t\t\tself.random_pad3 = RandomizeFrequencies(self.in3, self.in3+self.rand3, dim=3)\n","\n","\tdef call(self, x):\n","\n","\t\trand_paddings1 = [[0,0],\n","\t\t\t\t\t[0, self.rand1],\n","\t\t\t\t   [0, 0],\n","\t\t\t\t   [0, 0]]\n","\t\trand_paddings2 = [[0,0],\n","\t\t\t\t\t[0, 0],\n","\t\t\t\t   [0, self.rand2],\n","\t\t\t\t   [0, 0]]\n","\t\trand_paddings3 = [[0,0],\n","\t\t\t\t\t[0, 0],\n","\t\t\t\t   [0, 0],\n","\t\t\t\t   [0, self.rand3]]\n","\n","\t\tin_paddings1 = [[0, 0],\n","\t\t\t\t\t[self.in1, 0],\n","\t\t\t\t   [0, 0],\n","\t\t\t\t   [0, 0]]\n","\t\tin_paddings2 = [[0, 0],\n","\t\t\t\t\t[0, 0],\n","\t\t\t\t   [self.in2, 0],\n","\t\t\t\t   [0, 0]]\n","\t\tin_paddings3 = [[0, 0],\n","\t\t\t\t\t[0, 0],\n","\t\t\t\t   [0, 0],\n","\t\t\t\t   [self.in3, 0]]\n","\n","\t\t#https://github.com/tensorflow/probability/blob/88d217dfe8be49050362eb14ba3076c0dc0f1ba6/tensorflow_probability/python/distributions/normal.py#L174\n","\t\tif(self.distribution in [\"Normal\", \"VonMises\"]):\n","\t\t\trand_coefs = getattr(tfp.distributions, self.distribution)(self.loc, self.scale).sample()\n","\t\t\tif(self.distribution==\"VonMises\"):\n","\t\t\t\trand_coefs=tf.cos(rand_coefs)\n","\t\t\trand_coefs1, rand_coefs2, rand_coefs3 = tf.split(rand_coefs, [self.shape_normal1[0]*self.shape_normal1[1]*self.shape_normal1[2], self.shape_normal2[0]*self.shape_normal2[1]*self.shape_normal2[2], self.shape_normal3[0]*self.shape_normal3[1]*self.shape_normal3[2]], axis=-1)\n","\t\t\tbiases1, biases2, biases3 = tf.split(self.biases, [self.shape_normal1[0]*self.shape_normal1[1]*self.shape_normal1[2], self.shape_normal2[0]*self.shape_normal2[1]*self.shape_normal2[2], self.shape_normal3[0]*self.shape_normal3[1]*self.shape_normal3[2]], axis=-1)\n","\n","\t\tif(self.dependent):\n","\t\t\tx_cond1 = tf.squeeze(tf.matmul(tf.reshape(x, (tf.shape(x)[0], 1, tf.shape(x)[1]*tf.shape(x)[2]*tf.shape(x)[3],)), self.w1), axis=1)\n","\t\t\tx_cond2 = tf.squeeze(tf.matmul(tf.reshape(x, (tf.shape(x)[0], 1, tf.shape(x)[1]*tf.shape(x)[2]*tf.shape(x)[3],)), self.w2), axis=1)\n","\t\t\tx_cond3 = tf.squeeze(tf.matmul(tf.reshape(x, (tf.shape(x)[0], 1, tf.shape(x)[1]*tf.shape(x)[2]*tf.shape(x)[3],)), self.w3), axis=1)\n","\t\t\t#attention?\n","\t\t\tx_cond1 = tf.nn.softmax(x_cond1)\n","\t\t\tx_cond2 = tf.nn.softmax(x_cond2)\n","\t\t\tx_cond3 = tf.nn.softmax(x_cond3)\n","\t\t\trand_coefs1 = tf.matmul(x_cond1, biases1*rand_coefs1)#shape = [None, F] = [Batch, F]\n","\t\t\trand_coefs2 = tf.matmul(x_cond2, biases2*rand_coefs2)#shape = [None, F] = [Batch, F]\n","\t\t\trand_coefs3 = tf.matmul(x_cond3, biases3*rand_coefs3)#shape = [None, F] = [Batch, F]\n","\n","\t\trand_coefs1 = tf.reshape(rand_coefs1, (tf.shape(rand_coefs1)[0],)+self.shape_normal1)\n","\t\trand_coefs2 = tf.reshape(rand_coefs2, (tf.shape(rand_coefs2)[0],)+self.shape_normal2)\n","\t\trand_coefs3 = tf.reshape(rand_coefs3, (tf.shape(rand_coefs3)[0],)+self.shape_normal3)\n","\n","\t\tif(self.coefs_perturb):\n","\t\t\tdist_normal = tfp.distributions.Normal(loc=self.normal.distribution.loc, scale=self.normal.distribution.scale)\n","\t\t\tx = x*dist_normal.sample()\n","\n","\t\tif(self.random_padding):\n","\t\t\tz = self.random_pad1(x,rand_coefs1)\n","\t\t\tz = self.random_pad2(z,rand_coefs2)\n","\t\t\tz = self.random_pad3(z,rand_coefs3)\n","\t\telse:\n","\t\t\tz = tf.pad(x, rand_paddings1, constant_values=1.0)*tf.pad(rand_coefs1, in_paddings1, constant_values=1.0)\n","\t\t\tz = tf.pad(z, rand_paddings2, constant_values=1.0)*tf.pad(rand_coefs2, in_paddings2, constant_values=1.0)\n","\t\t\tz = tf.pad(z, rand_paddings3, constant_values=1.0)*tf.pad(rand_coefs3, in_paddings3, constant_values=1.0)\n","\n","\t\treturn self.padded_idct3(z)\n","\n","\tdef get_config(self):\n","\t\treturn {\n","\t\t\t\"in1\": self.in1,\n","\t\t\t\"in2\": self.in2,\n","\t\t\t\"in3\": self.in3,\n","\t\t\t\"out1\": self.out1,\n","\t\t\t\"out2\": self.out2,\n","\t\t\t\"out3\": self.out3,\n","\t\t\t\"rand1\": self.rand1,\n","\t\t\t\"rand2\": self.rand2,\n","\t\t\t\"rand3\": self.rand3,\n","\t\t\t\"coefs_perturb\": self.coefs_perturb,\n","\t\t\t\"dependent\": self.dependent,\n","\t\t\t\"posterior_dimension\": self.posterior_dimension,\n","\t\t\t\"distribution\": self.distribution,\n","\t\t\t\"random_padding\": self.random_padding,\n","\t\t}\n","\n","\t@classmethod\n","\tdef from_config(cls, config):\n","\t\treturn cls(**config)\n","\n","\n","\n","\n","\n","class SpectralDropout(tf.keras.layers.Layer):\n","\t\"\"\"\n","\tSpectral Dropout Layer - Khan et al. 2019 - https://www.sciencedirect.com/science/article/pii/S0893608018302715\n","\n","\ttfp.distributions.Bernoulli(probs=p)\n","\n","\t>>> import tensorflow as tf\n","\t>>> import tensorflow_probability as tfp\n","\t>>> layer = SpectralDropout(64,64,30,0.5)\n","\t>>> layer(tf.ones((1,64,64,30)))\n","\n","\t\"\"\"\n","\tdef __init__(self, in1, in2, in3, probs=None, dtype=tf.float32):\n","\t\t\"\"\"\n","\t\tin1 - int - first dimension input\n","\t\t\"\"\"\n","\n","\t\tsuper(SpectralDropout, self).__init__()\n","\n","\n","\t\tif(probs is None):\n","\t\t\tprobs=tf.constant(0.5, shape=(in1, in2, in3))\n","\t\t\tself.probs=self.add_weight('probs',\n","\t\t\t\t\t\t\t\tshape=[in1, in2, in3],\n","\t\t\t\t\t\t\t\tinitializer=tf.constant_initializer(probs.numpy()),\n","\t\t\t\t\t\t\t\tconstraint=tf.keras.constraints.NonNeg(),\n","\t\t\t\t\t\t\t\tdtype=tf.float32,\n","\t\t\t\t\t\t\t\ttrainable=False)#can not be trained since Bernoulli sampling is not differentiable\n","\t\telse:\n","\t\t\tself.probs=tf.constant_initializer(probs, shape=(in1, in2, in3))\n","\n","\t\tself.mask_dist = tfp.distributions.Bernoulli(probs=self.probs, dtype=dtype)\n","\n","\tdef call(self, X):\n","\t\treturn X*self.mask_dist.sample()\n","\n","\n","\n","\n","class RandomizeFrequencies(tf.keras.layers.Layer):\n","\t\"\"\"\n","\tRandomize the predicted frequencies and estimate the rest\n","\tJust like in fMRI enhancement\n","\n","\tThis is just like a padding, but instead of being reflected on the sides,\n","\tit specifies the positions of the X in the new representation in a random initialized order\n","\n","\t*dist* refers to the distribution used to order the coefficients\n","\t\"\"\"\n","\tdef __init__(self, in_shape, out_shape, dim, dist=\"Pareto\"):\n","\n","\t\tassert dim in [1,2,3], \"This layer only operates for 3D representations\"\n","\t\tassert out_shape > in_shape, \"The output shape has to be bigger than the input\"\n","\n","\t\tsuper(RandomizeFrequencies, self).__init__()\n","\n","\t\tself.in_shape=in_shape\n","\t\tself.out_shape=out_shape\n","\t\tself.dim=dim\n","\t\tself.dist=dist\n","\n","\t\tif(dist==\"Pareto\"):\n","\t\t\tdef p(a, size):\n","\t\t\t\t_p=(size*1**size)/(a**2)[1:]\n","\t\t\t\treturn np.exp(_p)/np.sum(np.exp(_p))\n","\t\telse:\n","\t\t\traise NotImplementedError\n","\n","\t\tself.shape1=np.sort(np.random.choice(np.arange(out_shape), p=p(np.arange(out_shape+1),1), size=in_shape, replace=False))\n","\n","\tdef call(self, X, C):\n","\t\t\"\"\"\n","\t\tlist of all splits of both X and C\n","\n","\t\t\t>>> from layers.fft import RandomizeFrequencies\n","\t\t\t>>> import tensorflow as tf\n","\t\t\t>>> a = tf.random.uniform((1,2,2,2))\n","\t\t\t>>> b = tf.random.uniform((1,2,2,2))\n","\t\t\t>>> randomize = RandomizeFrequencies(2, 4, dim=1)\n","\t\t\t>>> randomize(a,b)\n","\t\t\t>>> randomize.shape1\n","\t\t\t>>> a\n","\t\t\t>>> b\n","\n","\t\t\"\"\"\n","\n","\t\tZ=None\n","\t\tadded=0\n","\n","\t\tfor split in range(len(self.shape1)):\n","\t\t\tif(Z is None):\n","\t\t\t\tif(self.shape1[split]==0):\n","\t\t\t\t\tif(self.dim==1):\n","\t\t\t\t\t\tZ=X[:,split:split+1,:,:]\n","\t\t\t\t\telif(self.dim==2):\n","\t\t\t\t\t\tZ=X[:,:,split:split+1,:]\n","\t\t\t\t\telif(self.dim==3):\n","\t\t\t\t\t\tZ=X[:,:,:,split:split+1]\n","\t\t\t\t\telse:\n","\t\t\t\t\t\traise NotImplementedError\n","\t\t\t\telse:\n","\t\t\t\t\tif(self.dim==1):\n","\t\t\t\t\t\tZ=tf.concat([C[:,:self.shape1[split],:,:], X[:,split:split+1,:,:]], axis=self.dim)\n","\t\t\t\t\telif(self.dim==2):\n","\t\t\t\t\t\tZ=tf.concat([C[:,:,:self.shape1[split],:], X[:,:,split:split+1,:]], axis=self.dim)\n","\t\t\t\t\telif(self.dim==3):\n","\t\t\t\t\t\tZ=tf.concat([C[:,:,:,:self.shape1[split]], X[:,:,:,split:split+1]], axis=self.dim)\n","\t\t\t\t\telse:\n","\t\t\t\t\t\traise NotImplementedError\n","\t\t\t\t\tadded+=self.shape1[split]\n","\n","\t\t\telse:\n","\n","\t\t\t\tdiff=self.shape1[split]-self.shape1[split-1]-1\n","\t\t\t\tif(self.dim==1):\n","\t\t\t\t\tZ=tf.concat([Z,C[:,added:added+diff,:,:]], axis=self.dim)\n","\t\t\t\telif(self.dim==2):\n","\t\t\t\t\tZ=tf.concat([Z,C[:,:,added:added+diff,:]], axis=self.dim)\n","\t\t\t\telif(self.dim==3):\n","\t\t\t\t\tZ=tf.concat([Z,C[:,:,:,added:added+diff]], axis=self.dim)\n","\t\t\t\telse:\n","\t\t\t\t\traise NotImplementedError\n","\n","\t\t\t\tadded+=self.shape1[split]-self.shape1[split-1]-1\n","\n","\t\t\t\tif(self.dim==1):\n","\t\t\t\t\tZ=tf.concat([Z,X[:,split:split+1,:,:]], axis=self.dim)\n","\t\t\t\telif(self.dim==2):\n","\t\t\t\t\tZ=tf.concat([Z,X[:,:,split:split+1,:]], axis=self.dim)\n","\t\t\t\telif(self.dim==3):\n","\t\t\t\t\tZ=tf.concat([Z,X[:,:,:,split:split+1]], axis=self.dim)\n","\t\t\t\telse:\n","\t\t\t\t\traise NotImplementedError\n","\n","\t\tif(tf.shape(Z)[self.dim] < self.out_shape):\n","\t\t\tif(self.dim==1):\n","\t\t\t\tZ=tf.concat([Z,C[:,added:,:,:]], axis=self.dim)\n","\t\t\telif(self.dim==2):\n","\t\t\t\tZ=tf.concat([Z,C[:,:,added:,:]], axis=self.dim)\n","\t\t\telif(self.dim==3):\n","\t\t\t\tZ=tf.concat([Z,C[:,:,:,added:]], axis=self.dim)\n","\t\t\telse:\n","\t\t\t\traise NotImplementedError\n","\t\treturn Z\n","\n","\tdef get_config(self):\n","\t\treturn {\n","\t\t\t\"in_shape\": self.in_shape,\n","\t\t\t\"out_shape\": self.out_shape,\n","\t\t\t\"dim\": self.dim,\n","\t\t\t\"dist\": self.dist,\n","\t\t}\n","\n","\t@classmethod\n","\tdef from_config(cls, config):\n","\t\treturn cls(**config)\n"]},{"cell_type":"code","source":["from scipy.signal import resample\n","from scipy.stats import zscore\n","\n","def stft(eeg, channel=0, window_size=2, fs=250, limit=False, f_limit=134, start_time=None, stop_time=None):\n","\tsignal = eeg[channel][:]\n","\tif(type(signal) is tuple):\n","\t\tsignal, _ = signal\n","\t\tsignal = signal.reshape((signal.shape[1]))\n","\telse:\n","\t\tsignal = signal.reshape((signal.shape[0]))\n","\n","\n","\tif(start_time == None):\n","\t\tstart_time = 0\n","\tif(stop_time == None):\n","\t\tstop_time = len(signal)\n","\tsignal = signal[start_time:stop_time]\n","\n","\tt = []\n","\n","\n","\n","\tfs_window_size = int(window_size*fs)\n","\n","\n","\tZ = []\n","\tseconds = 0\n","\tfor time in range(start_time, stop_time, fs_window_size)[:-1]:\n","\t\tfft1 = compute_fft(signal[time:time+fs_window_size], fs=fs, limit=limit, f_limit=f_limit)\n","\n","\t\tN = len(signal[time:time+fs_window_size])/2\n","\t\tf = np.linspace (0, len(fft1), int(N/2))\n","\n","\t\t#average\n","\t\tZ += [list(abs(fft1[1:]))]\n","\t\tt += [seconds]\n","\t\tseconds += window_size\n","\n","\treturn f[1:], np.transpose(np.array(Z)), t"],"metadata":{"id":"kE6zCY6K5v8v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","from torch.utils.data import Dataset\n","import math\n","import numpy as np\n","import nibabel.processing\n","from nilearn import image, masking\n","import nibabel as nib\n","import mne\n","import json\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","from skimage.transform import resize\n","import matplotlib.pyplot as plt\n","\n","def fmri_norm(volume, scaler=StandardScaler()):\n","  # flatten = volume.flatten().reshape((-1, 1))\n","  # normed = scaler.fit_transform(flatten).reshape(volume.shape)\n","  normed = (volume - np.mean(volume, axis=(0, 1), keepdims=True)) / np.std(volume, axis=(0, 1), keepdims=True)\n","  assert normed.max() <= 1 and normed.min() >= 0\n","  return normed\n","\n","# example = image.load_img('sub-xp201/func/sub-xp201_task-1dNF_run-01_bold.nii.gz')\n","# img = np.swapaxes(np.swapaxes(np.swapaxes(fmri_norm(example.get_fdata()), 0, 3), 1,2), 1,3)\n","# dct = DCT3D(*img.shape[1:])\n","# downsample_shape = (64, 64, 30)\n","# idct = padded_iDCT3D(*(downsample_shape[:2]+(img.shape[3],)+downsample_shape))\n","# resampled = image.new_img_like(example, np.swapaxes(np.swapaxes(np.swapaxes(idct(dct(img).numpy()[:, :downsample_shape[0], :downsample_shape[1], :]).numpy(), 0, 3), 0,2), 0,1))\n"],"metadata":{"id":"vATMWG_BMDjT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["d = resampled.get_fdata()\n","plt.imshow(d[:, :, 20, 35], cmap='gray')\n","plt.colorbar()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":450},"id":"Q8hm1ofuM7qp","executionInfo":{"status":"ok","timestamp":1701565675405,"user_tz":480,"elapsed":636,"user":{"displayName":"Jiaqi Wu","userId":"00803091932349494936"}},"outputId":"44efcdc8-88dd-45fe-fb3c-57b0b2b765c2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.colorbar.Colorbar at 0x7ff4cfa6f2e0>"]},"metadata":{},"execution_count":14},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A1WJTgWNFGeX"},"outputs":[],"source":["from torch.utils.data import Dataset\n","import math\n","import numpy as np\n","import nibabel.processing\n","from nilearn import image, masking\n","import nibabel as nib\n","import mne\n","import json\n","import os\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","from skimage.transform import resize\n","import matplotlib.pyplot as plt\n","from scipy import ndimage\n","\n","def fmri_norm(volume, scaler=StandardScaler()):\n","  # flatten = volume.flatten().reshape((-1, 1))\n","  # normed = scaler.fit_transform(flatten).reshape(volume.shape)\n","  mini = np.min(volume, axis=(0, 1), keepdims=True)\n","  maxi = np.max(volume, axis=(0, 1), keepdims=True)\n","  normed = (volume - mini) / (maxi - mini)\n","  assert normed.max() <= 1 and normed.min() >= 0\n","  return normed\n","\n","scaler = StandardScaler()\n","\n","def get_eeg_subjects(dir=\"/content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338\"):\n","    # eeg files are inside 'derivatives'\n","    eeg_root = os.path.join(dir, 'derivatives')\n","    fmri_root = dir\n","    eeg_subjects = [f for f in os.listdir(eeg_root) if 'sub' in f]\n","    # print(eeg_subjects)\n","    _1dNF_paths = []\n","    _2dNF_paths = []\n","    _pre_paths = []\n","    _post_paths = []\n","    eeg_fmri_table = {}\n","    for sub in eeg_subjects:\n","      path = os.path.join(eeg_root, sub, 'eeg_pp')\n","      experiment_files = [f for f in os.listdir(path) if 'vhdr' in f]\n","      # print(experiment_files)\n","\n","      fmri_path = os.path.join(fmri_root, sub, 'func')\n","\n","      for exp in experiment_files:\n","        eeg_p = os.path.join(path, exp)\n","        if '1dNF' in exp:\n","          _1dNF_paths.append(eeg_p)\n","          if 'run-01' in exp:\n","            fmri_p = os.path.join(fmri_path, f'{sub}_task-1dNF_run-01_bold.nii.gz')\n","          elif 'run-02' in exp:\n","            fmri_p = os.path.join(fmri_path, f'{sub}_task-1dNF_run-02_bold.nii.gz')\n","          else:\n","            fmri_p = os.path.join(fmri_path, f'{sub}_task-1dNF_run-03_bold.nii.gz')\n","        elif '2dNF' in exp:\n","          _2dNF_paths.append(eeg_p)\n","          if 'run-01' in exp:\n","            fmri_p = os.path.join(fmri_path, f'{sub}_task-2dNF_run-01_bold.nii.gz')\n","          elif 'run-02' in exp:\n","            fmri_p = os.path.join(fmri_path, f'{sub}_task-2dNF_run-02_bold.nii.gz')\n","          else:\n","            fmri_p = os.path.join(fmri_path, f'{sub}_task-2dNF_run-03_bold.nii.gz')\n","        else: # control\n","          if 'post' in exp:\n","            _post_paths.append(eeg_p)\n","            fmri_p = os.path.join(fmri_path, f'{sub}_task-MIpost_bold.nii.gz')\n","          else:\n","            _pre_paths.append(eeg_p)\n","            fmri_p = os.path.join(fmri_path, f'{sub}_task-MIpre_bold.nii.gz')\n","\n","        eeg_fmri_table[eeg_p] = fmri_p\n","\n","    return _1dNF_paths, _2dNF_paths, _pre_paths, _post_paths, eeg_fmri_table\n","\n","def resize_volume(img, desired_depth=32, desired_width=64, desired_height=64):\n","    \"\"\"Resize across z-axis\"\"\"\n","    # Set the desired depth\n","    # Get current depth\n","    current_depth = img.shape[0]\n","    current_width = img.shape[1]\n","    current_height = img.shape[2]\n","    # Compute depth factor\n","    depth = current_depth / desired_depth\n","    width = current_width / desired_width\n","    height = current_height / desired_height\n","    depth_factor = 1 / depth\n","    width_factor = 1 / width\n","    height_factor = 1 / height\n","    # Rotate\n","    # img = ndimage.rotate(img, 90, reshape=False)\n","\n","    img = ndimage.zoom(img, (depth_factor, height_factor, width_factor), order=1)\n","    return img\n","\n","def eeg_process(eeg):\n","  len_channels = len(eeg.ch_names)\n","  x_instance = []\n","  #eeg\n","  for channel in range(len_channels):\n","      print(\"Before stft, eeg shape: \", eeg.get_data().shape)\n","      f, Zxx, t = stft(eeg, channel=channel, window_size=200, fs=200, limit=eeg_limit, f_limit=eeg_f_limit)\n","      print(\"data_util eeg processing..??\")\n","      print(Zxx.shape)\n","      x_instance += [Zxx]\n","  return zscore(np.array(x_instance))\n","\n","def parse_one_file(eeg_signal, fmri, start_time, end_time, pre_post, window=5, sampling_rate=200, lag=0, ifresize=True):\n","    result_eeg = []\n","    result_fmri = []\n","    # if ifresize:\n","      # img = np.swapaxes(np.swapaxes(np.swapaxes(fmri.get_fdata(), 0, 3), 1,2), 1,3)\n","      # dct = DCT3D(*img.shape[1:])\n","      # downsample_shape = (64, 64, 32)\n","      # idct = padded_iDCT3D(*(downsample_shape[:2]+(img.shape[3],)+downsample_shape))\n","      # resampled = image.new_img_like(fmri, np.swapaxes(np.swapaxes(np.swapaxes(idct(dct(img).numpy()[:, :downsample_shape[0], :downsample_shape[1], :]).numpy(), 0, 3), 0,2), 0,1))\n","      # print(\"Finished resampling... shape is \", resampled.get_fdata().shape)\n","      # fmri = resampled.get_fdata()\n","\n","    fmri = fmri.get_fdata()\n","\n","    step = window*sampling_rate\n","    scaler = StandardScaler()\n","    if pre_post:\n","      step = sampling_rate*2 # shorter step due to insufficient data\n","\n","    for t in range(start_time, end_time, step):\n","\n","        f, Zxx, t = stft(eeg, channel=channel, window_size=200, limit=eeg_limit, f_limit=eeg_f_limit)\n","\n","        # s = np.array(eeg_signal[:, t:t+sampling_rate]) # take 1 second of eeg data, considering the potential size of model\n","        # assert s.shape == (64, 200)\n","        # eeg normalization??\n","        # mini = np.min(s, axis=1, keepdims=True)\n","        # maxi = np.max(s, axis=1, keepdims=True)\n","        # normed = (s - mini) / (maxi - mini)\n","        print(Zxx.shape)\n","        result_eeg.append(Zxx)\n","\n","        # fmri slice normalization + resample\n","        fmri_slice_start = math.ceil(start_time/sampling_rate)\n","        sub_volume = np.array(fmri[:, :, :, lag+fmri_slice_start:lag+fmri_slice_start+window]) # 104, 106, 16\n","        sub_volume = np.mean(sub_volume, axis=-1)\n","        # print(sub_volume.shape)\n","        assert sub_volume.shape == (fmri.shape[:3])\n","        h, w, d = sub_volume.shape\n","        sub_volume = np.swapaxes(np.swapaxes(sub_volume, 0, 2), 1, 2)\n","\n","        normed = resize_volume(fmri_norm(sub_volume, scaler))\n","        assert normed.shape == (32, 64, 64)\n","        # print(normed.shape)\n","        result_fmri.append(normed)\n","    # print(\"Finished parsing\")\n","    # print(np.array(result_eeg).shape)\n","    # print(np.array(result_fmri).shape)\n","    print(\"Finished parsing one file\")\n","    return result_eeg, result_fmri\n","\n","def extract_eeg_fmri_pairs_one_file(raw_eeg, raw_fmri, target_code=2, rest_code=99, pre_post=False, ratio = 0.9):\n","    events, annotations = mne.events_from_annotations(raw_eeg)\n","    signal = raw_eeg.get_data()\n","    all_eeg = []\n","    all_fmri = []\n","    start = None\n","    end = None\n","    find_start = False\n","    start_end_times = []\n","    for time, _, event_code in events:\n","        if event_code == target_code:\n","            # this is a task trial\n","            start = time\n","            find_start = True\n","        elif event_code == rest_code and find_start:\n","            # print(\"Find the end of a stimulus event: \")\n","            # print(f\"Start: {start}; End: {time}\")\n","            start_end_times.append(str([start, time]))\n","            eeg_fragments, fmri_fragments = parse_one_file(signal, raw_fmri, start, time, pre_post=pre_post)\n","            all_eeg.extend(eeg_fragments)\n","            all_fmri.extend(fmri_fragments)\n","            find_start = False\n","\n","    p = np.random.permutation(len(all_eeg))\n","    all_eeg = np.array(all_eeg)[p]\n","    all_fmri = np.array(all_fmri)[p]\n","    # eeg_mu = all_eeg.mean()\n","    # eeg_sig = all_eeg.std()\n","    mini = np.min(all_eeg)\n","    maxi = np.max(all_eeg)\n","    all_eeg = (all_eeg - mini) / (maxi - mini)\n","\n","    # eeg  z-score normalize\n","    train_eeg = np.array(all_eeg[:int(all_eeg.shape[0]*ratio)])\n","    test_eeg = np.array(all_eeg[int(all_eeg.shape[0]*ratio):])\n","    train_fmri = np.array(all_fmri[:int(all_fmri.shape[0]*ratio)])\n","    test_fmri = np.array(all_fmri[int(all_fmri.shape[0]*ratio):])\n","    return train_eeg, train_fmri, test_eeg, test_fmri, start_end_times\n","\n","\n","def segment_data(dataset_table):\n","    all_subject_eeg_train = []\n","    all_subject_eeg_test = []\n","    all_subject_fmri_train = []\n","    all_subject_fmri_test = []\n","    all_subject_label_train = []\n","    all_subject_label_test = []\n","    inf = {}\n","    for eeg_file in dataset_table.keys():\n","      print(f\"=====>>>> Segmenting {eeg_file}\")\n","      eeg = mne.io.read_raw_brainvision(eeg_file)\n","      events, annotations = mne.events_from_annotations(eeg)\n","      # print(events[:10])\n","      try:\n","        fmri_img = image.load_img(dataset_table[eeg_file])\n","      except:\n","        print(f\"Failed to load {dataset_table[eeg_file]}... Skipping it\")\n","        continue\n","      if '1dNF' in eeg_file:\n","        label = 0\n","      elif '2dNF' in eeg_file:\n","        label = 1\n","      elif 'pre' in eeg_file:\n","        label = 2\n","      else:\n","        label = 3\n","      eeg_seg_train, fmri_seg_train, eeg_seg_test, fmri_seg_test, times = extract_eeg_fmri_pairs_one_file(eeg, fmri_img) # one subject\n","      inf[eeg_file] = times\n","      all_subject_eeg_train.extend(eeg_seg_train)\n","      all_subject_eeg_test.extend(eeg_seg_test)\n","\n","      all_subject_fmri_train.extend(fmri_seg_train)\n","      all_subject_fmri_test.extend(fmri_seg_test)\n","      all_subject_label_train.extend([label]*len(eeg_seg_train))\n","      all_subject_label_test.extend([label]*len(eeg_seg_test))\n","\n","    # permute\n","    p = np.random.permutation(len(all_subject_eeg_train))\n","    all_subject_eeg_train = np.stack(all_subject_eeg_train, axis=0)[p]\n","    all_subject_fmri_train = np.stack(all_subject_fmri_train, axis=0)[p]\n","    all_subject_label_train = np.array(all_subject_label_train)[p]\n","\n","    p = np.random.permutation(len(all_subject_eeg_test))\n","    all_subject_eeg_test = np.stack(all_subject_eeg_test, axis=0)[p]\n","    all_subject_fmri_test = np.stack(all_subject_fmri_test, axis=0)[p]\n","    all_subject_label_test = np.array(all_subject_label_test)[p]\n","    with open('times.json', 'w') as fr:\n","      json.dump(inf, fr, indent=4)\n","\n","    return np.expand_dims(all_subject_eeg_train, axis=1), np.expand_dims(all_subject_eeg_test, axis=1), np.expand_dims(all_subject_fmri_train, axis=1), np.expand_dims(all_subject_fmri_test, axis=1), all_subject_label_train, all_subject_label_test\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FXR0SlohpBi2","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cbc3aa65-44c8-460a-a18f-70223ec9505d","executionInfo":{"status":"ok","timestamp":1701761172124,"user_tz":480,"elapsed":221012,"user":{"displayName":"Jiaqi Wu","userId":"00803091932349494936"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp201/eeg_pp/d_sub-xp201_task-1dNF_run-01_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp201/eeg_pp/d_sub-xp201_task-1dNF_run-01_eeg_pp.vhdr...\n","Setting channel info structure...\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp201/eeg_pp/d_sub-xp201_task-1dNF_run-02_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp201/eeg_pp/d_sub-xp201_task-1dNF_run-02_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp201/eeg_pp/d_sub-xp201_task-1dNF_run-03_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp201/eeg_pp/d_sub-xp201_task-1dNF_run-03_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp201/eeg_pp/d_sub-xp201_task-MIpost_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp201/eeg_pp/d_sub-xp201_task-MIpost_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp201/eeg_pp/d_sub-xp201_task-MIpre_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp201/eeg_pp/d_sub-xp201_task-MIpre_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'Stimulus/S101', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'Stimulus/S101', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp202/eeg_pp/d_sub-xp202_task-1dNF_run-01_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp202/eeg_pp/d_sub-xp202_task-1dNF_run-01_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp202/eeg_pp/d_sub-xp202_task-1dNF_run-02_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp202/eeg_pp/d_sub-xp202_task-1dNF_run-02_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp202/eeg_pp/d_sub-xp202_task-1dNF_run-03_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp202/eeg_pp/d_sub-xp202_task-1dNF_run-03_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp202/eeg_pp/d_sub-xp202_task-MIpost_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp202/eeg_pp/d_sub-xp202_task-MIpost_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp203/eeg_pp/d_sub-xp203_task-1dNF_run-01_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp203/eeg_pp/d_sub-xp203_task-1dNF_run-01_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'Stimulus/S101', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'Stimulus/S101', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp203/eeg_pp/d_sub-xp203_task-1dNF_run-02_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp203/eeg_pp/d_sub-xp203_task-1dNF_run-02_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp203/eeg_pp/d_sub-xp203_task-1dNF_run-03_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp203/eeg_pp/d_sub-xp203_task-1dNF_run-03_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp203/eeg_pp/d_sub-xp203_task-MIpost_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp203/eeg_pp/d_sub-xp203_task-MIpost_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'Stimulus/S101', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'Stimulus/S101', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp203/eeg_pp/d_sub-xp203_task-MIpre_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp203/eeg_pp/d_sub-xp203_task-MIpre_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp204/eeg_pp/d_sub-xp204_task-2dNF_run-01_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp204/eeg_pp/d_sub-xp204_task-2dNF_run-01_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp204/eeg_pp/d_sub-xp204_task-2dNF_run-02_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp204/eeg_pp/d_sub-xp204_task-2dNF_run-02_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp204/eeg_pp/d_sub-xp204_task-2dNF_run-03_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp204/eeg_pp/d_sub-xp204_task-2dNF_run-03_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp204/eeg_pp/d_sub-xp204_task-MIpost_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp204/eeg_pp/d_sub-xp204_task-MIpost_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp204/eeg_pp/d_sub-xp204_task-MIpre_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp204/eeg_pp/d_sub-xp204_task-MIpre_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp205/eeg_pp/d_sub-xp205_task-2dNF_run-01_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp205/eeg_pp/d_sub-xp205_task-2dNF_run-01_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp205/eeg_pp/d_sub-xp205_task-2dNF_run-02_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp205/eeg_pp/d_sub-xp205_task-2dNF_run-02_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp205/eeg_pp/d_sub-xp205_task-2dNF_run-03_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp205/eeg_pp/d_sub-xp205_task-2dNF_run-03_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp205/eeg_pp/d_sub-xp205_task-MIpost_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp205/eeg_pp/d_sub-xp205_task-MIpost_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp205/eeg_pp/d_sub-xp205_task-MIpre_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp205/eeg_pp/d_sub-xp205_task-MIpre_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp206/eeg_pp/d_sub-xp206_task-1dNF_run-01_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp206/eeg_pp/d_sub-xp206_task-1dNF_run-01_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp206/eeg_pp/d_sub-xp206_task-1dNF_run-02_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp206/eeg_pp/d_sub-xp206_task-1dNF_run-02_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp206/eeg_pp/d_sub-xp206_task-1dNF_run-03_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp206/eeg_pp/d_sub-xp206_task-1dNF_run-03_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'Stimulus/S101', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'Stimulus/S101', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp206/eeg_pp/d_sub-xp206_task-MIpost_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp206/eeg_pp/d_sub-xp206_task-MIpost_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp206/eeg_pp/d_sub-xp206_task-MIpre_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp206/eeg_pp/d_sub-xp206_task-MIpre_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp207/eeg_pp/d_sub-xp207_task-2dNF_run-01_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp207/eeg_pp/d_sub-xp207_task-2dNF_run-01_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp207/eeg_pp/d_sub-xp207_task-2dNF_run-02_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp207/eeg_pp/d_sub-xp207_task-2dNF_run-02_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp207/eeg_pp/d_sub-xp207_task-2dNF_run-03_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp207/eeg_pp/d_sub-xp207_task-2dNF_run-03_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp207/eeg_pp/d_sub-xp207_task-MIpost_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp207/eeg_pp/d_sub-xp207_task-MIpost_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp207/eeg_pp/d_sub-xp207_task-MIpre_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp207/eeg_pp/d_sub-xp207_task-MIpre_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp210/eeg_pp/d_sub-xp210_task-2dNF_run-01_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp210/eeg_pp/d_sub-xp210_task-2dNF_run-01_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp210/eeg_pp/d_sub-xp210_task-2dNF_run-02_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp210/eeg_pp/d_sub-xp210_task-2dNF_run-02_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp210/eeg_pp/d_sub-xp210_task-2dNF_run-03_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp210/eeg_pp/d_sub-xp210_task-2dNF_run-03_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Failed to load /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/sub-xp210/func/sub-xp210_task-2dNF_run-03_bold.nii.gz... Skipping it\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp210/eeg_pp/d_sub-xp210_task-MIpost_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp210/eeg_pp/d_sub-xp210_task-MIpost_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n","<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp210/eeg_pp/d_sub-xp210_task-MIpre_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp210/eeg_pp/d_sub-xp210_task-MIpre_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp211/eeg_pp/d_sub-xp211_task-1dNF_run-01_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp211/eeg_pp/d_sub-xp211_task-1dNF_run-01_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp211/eeg_pp/d_sub-xp211_task-1dNF_run-03_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp211/eeg_pp/d_sub-xp211_task-1dNF_run-03_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp211/eeg_pp/d_sub-xp211_task-MIpost_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp211/eeg_pp/d_sub-xp211_task-MIpost_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp211/eeg_pp/d_sub-xp211_task-MIpre_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp211/eeg_pp/d_sub-xp211_task-MIpre_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp213/eeg_pp/d_sub-xp213_task-2dNF_run-01_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp213/eeg_pp/d_sub-xp213_task-2dNF_run-01_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'Stimulus/S101', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'Stimulus/S101', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp213/eeg_pp/d_sub-xp213_task-2dNF_run-02_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp213/eeg_pp/d_sub-xp213_task-2dNF_run-02_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp213/eeg_pp/d_sub-xp213_task-2dNF_run-03_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp213/eeg_pp/d_sub-xp213_task-2dNF_run-03_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp213/eeg_pp/d_sub-xp213_task-MIpost_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp213/eeg_pp/d_sub-xp213_task-MIpost_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp213/eeg_pp/d_sub-xp213_task-MIpre_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp213/eeg_pp/d_sub-xp213_task-MIpre_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'Stimulus/S101', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'Stimulus/S101', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp216/eeg_pp/d_sub-xp216_task-2dNF_run-01_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp216/eeg_pp/d_sub-xp216_task-2dNF_run-01_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp216/eeg_pp/d_sub-xp216_task-2dNF_run-02_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp216/eeg_pp/d_sub-xp216_task-2dNF_run-02_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp216/eeg_pp/d_sub-xp216_task-2dNF_run-03_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp216/eeg_pp/d_sub-xp216_task-2dNF_run-03_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp216/eeg_pp/d_sub-xp216_task-MIpost_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp216/eeg_pp/d_sub-xp216_task-MIpost_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp216/eeg_pp/d_sub-xp216_task-MIpre_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp216/eeg_pp/d_sub-xp216_task-MIpre_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp217/eeg_pp/d_sub-xp217_task-2dNF_run-01_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp217/eeg_pp/d_sub-xp217_task-2dNF_run-01_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp217/eeg_pp/d_sub-xp217_task-2dNF_run-02_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp217/eeg_pp/d_sub-xp217_task-2dNF_run-02_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp217/eeg_pp/d_sub-xp217_task-2dNF_run-03_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp217/eeg_pp/d_sub-xp217_task-2dNF_run-03_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp217/eeg_pp/d_sub-xp217_task-MIpost_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp217/eeg_pp/d_sub-xp217_task-MIpost_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp217/eeg_pp/d_sub-xp217_task-MIpre_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp217/eeg_pp/d_sub-xp217_task-MIpre_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp218/eeg_pp/d_sub-xp218_task-1dNF_run-01_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp218/eeg_pp/d_sub-xp218_task-1dNF_run-01_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp218/eeg_pp/d_sub-xp218_task-1dNF_run-02_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp218/eeg_pp/d_sub-xp218_task-1dNF_run-02_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp218/eeg_pp/d_sub-xp218_task-1dNF_run-03_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp218/eeg_pp/d_sub-xp218_task-1dNF_run-03_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp218/eeg_pp/d_sub-xp218_task-MIpost_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp218/eeg_pp/d_sub-xp218_task-MIpost_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp218/eeg_pp/d_sub-xp218_task-MIpre_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp218/eeg_pp/d_sub-xp218_task-MIpre_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp219/eeg_pp/d_sub-xp219_task-1dNF_run-01_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp219/eeg_pp/d_sub-xp219_task-1dNF_run-01_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp219/eeg_pp/d_sub-xp219_task-1dNF_run-02_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp219/eeg_pp/d_sub-xp219_task-1dNF_run-02_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'Stimulus/S101', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'Stimulus/S101', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp219/eeg_pp/d_sub-xp219_task-1dNF_run-03_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp219/eeg_pp/d_sub-xp219_task-1dNF_run-03_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Failed to load /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/sub-xp219/func/sub-xp219_task-1dNF_run-03_bold.nii.gz... Skipping it\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp219/eeg_pp/d_sub-xp219_task-MIpost_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp219/eeg_pp/d_sub-xp219_task-MIpost_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n","<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp219/eeg_pp/d_sub-xp219_task-MIpre_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp219/eeg_pp/d_sub-xp219_task-MIpre_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp220/eeg_pp/d_sub-xp220_NF4_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp220/eeg_pp/d_sub-xp220_NF4_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp220/eeg_pp/d_sub-xp220_task-1dNF_run-01_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp220/eeg_pp/d_sub-xp220_task-1dNF_run-01_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp220/eeg_pp/d_sub-xp220_task-1dNF_run-02_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp220/eeg_pp/d_sub-xp220_task-1dNF_run-02_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp220/eeg_pp/d_sub-xp220_task-1dNF_run-03_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp220/eeg_pp/d_sub-xp220_task-1dNF_run-03_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'Stimulus/S101', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'Stimulus/S101', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp220/eeg_pp/d_sub-xp220_task-MIpost_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp220/eeg_pp/d_sub-xp220_task-MIpost_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp220/eeg_pp/d_sub-xp220_task-MIpre_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp220/eeg_pp/d_sub-xp220_task-MIpre_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp221/eeg_pp/d_sub-xp221_task-2dNF_run-01_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp221/eeg_pp/d_sub-xp221_task-2dNF_run-01_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp221/eeg_pp/d_sub-xp221_task-2dNF_run-02_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp221/eeg_pp/d_sub-xp221_task-2dNF_run-02_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp221/eeg_pp/d_sub-xp221_task-2dNF_run-03_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp221/eeg_pp/d_sub-xp221_task-2dNF_run-03_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp221/eeg_pp/d_sub-xp221_task-MIpost_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp221/eeg_pp/d_sub-xp221_task-MIpost_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp221/eeg_pp/d_sub-xp221_task-MIpre_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp221/eeg_pp/d_sub-xp221_task-MIpre_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 35', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 35', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp222/eeg_pp/d_sub-xp222_task-1dNF_run-01_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp222/eeg_pp/d_sub-xp222_task-1dNF_run-01_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp222/eeg_pp/d_sub-xp222_task-1dNF_run-02_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp222/eeg_pp/d_sub-xp222_task-1dNF_run-02_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp222/eeg_pp/d_sub-xp222_task-1dNF_run-03_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp222/eeg_pp/d_sub-xp222_task-1dNF_run-03_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp222/eeg_pp/d_sub-xp222_task-MIpost_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp222/eeg_pp/d_sub-xp222_task-MIpost_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'Stimulus/S101', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'Stimulus/S101', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","=====>>>> Segmenting /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp222/eeg_pp/d_sub-xp222_task-MIpre_eeg_pp.vhdr\n","Extracting parameters from /content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338/derivatives/sub-xp222/eeg_pp/d_sub-xp222_task-MIpre_eeg_pp.vhdr...\n","Setting channel info structure...\n","Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'Stimulus/S101', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a8fedfa92e59>:194: RuntimeWarning: No coordinate information found for channels ['ECG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n","  eeg = mne.io.read_raw_brainvision(eeg_file)\n"]},{"output_type":"stream","name":"stdout","text":["Used Annotations descriptions: ['New Segment/', 'Pulse Artifact/R', 'Response/R128', 'Stimulus/S  2', 'Stimulus/S 99', 'Stimulus/S101', 'TPULSE/TEND', 'TPULSE/TPEAK', 'TPULSE/TSTART', 'Time 0/']\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n","Finished parsing one file\n"]}],"source":["_1dNF, _2dNF, pre, post, dataset_table = get_eeg_subjects(dir=\"/content/drive/MyDrive/EEG_GAN/datasets/datasets/ds002338\")\n","\n","# train test splitted\n","train_e, test_e, train_f, test_f, train_l, test_l = segment_data(dataset_table)\n"]},{"cell_type":"code","source":["\n","print(train_e.shape, train_f.shape, test_e.shape, test_f.shape)\n","print(train_e.min(), train_e.max())\n","print(train_f.min(), train_f.max())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BGmffLm1gj07","executionInfo":{"status":"ok","timestamp":1701754203377,"user_tz":480,"elapsed":830,"user":{"displayName":"Jiaqi Wu","userId":"00803091932349494936"}},"outputId":"479fc530-e9a0-4ac3-816f-6cb2c695bbc3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(2084, 1, 64, 200) (2084, 1, 32, 64, 64) (251, 1, 64, 200) (251, 1, 32, 64, 64)\n","0.0 1.0\n","-1.0 1.0\n"]}]},{"cell_type":"code","source":["example_f = train_f[100][0][2]\n","plt.imshow(example_f, cmap='gray')"],"metadata":{"id":"FBx6IqXp-fwq","colab":{"base_uri":"https://localhost:8080/","height":450},"executionInfo":{"status":"ok","timestamp":1701754208197,"user_tz":480,"elapsed":843,"user":{"displayName":"Jiaqi Wu","userId":"00803091932349494936"}},"outputId":"b917d2db-bc7a-43e5-d2bb-8c20137d2f75"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7dde0daf75b0>"]},"metadata":{},"execution_count":103},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["from matplotlib import pyplot as plt\n","import matplotlib as mpl\n","num = 2250\n","plt.title('label:'+str(train_l[num]))\n","plt.imshow(train_f[num][:,:,10], cmap='gray')"],"metadata":{"id":"-T2onGoxj7NI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":183},"id":"8xgcZICtqTFP","executionInfo":{"status":"error","timestamp":1701456771188,"user_tz":480,"elapsed":5,"user":{"displayName":"Binxu Li","userId":"09571138878201922493"}},"outputId":"e8ff5a80-ca8d-4c32-8ede-77ea23c7c8e5"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-99f16d9951d3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'test_f' is not defined"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_sdmKNzosmcs","outputId":"c530ab2e-d805-4674-d7fc-4796d99a07b1","executionInfo":{"status":"ok","timestamp":1701420343468,"user_tz":480,"elapsed":11,"user":{"displayName":"Binxu Li","userId":"09571138878201922493"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(328, 64, 200)"]},"metadata":{},"execution_count":16}],"source":["import torch\n","import numpy as np\n","test_ee = np.stack(test_e, axis=0)\n","test_ee.shape"]},{"cell_type":"markdown","metadata":{"id":"MJxQafmUwaFa"},"source":["# Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rdvCOerssuHa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701761177113,"user_tz":480,"elapsed":5009,"user":{"displayName":"Jiaqi Wu","userId":"00803091932349494936"}},"outputId":"c36a28df-d45e-4ee4-f536-19b269a93cbe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.7.0)\n"]}],"source":["\"\"\"\n","EEG Conformer\n","\n","Convolutional Transformer for EEG decoding\n","\n","Couple CNN and Transformer in a concise manner with amazing results\n","\"\"\"\n","# remember to change paths\n","\n","import argparse\n","import os\n","# gpus = [0]\n","# os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n","# os.environ[\"CUDA_VISIBLE_DEVICES\"] = ','.join(map(str, gpus))\n","import numpy as np\n","import math\n","import glob\n","import random\n","import itertools\n","import datetime\n","import time\n","import datetime\n","import sys\n","import scipy.io\n","\n","import torchvision.transforms as transforms\n","from torchvision.utils import save_image, make_grid\n","\n","from torch.utils.data import DataLoader\n","from torch.autograd import Variable\n","# from torchsummary import summary\n","import torch.autograd as autograd\n","from torchvision.models import vgg19\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch\n","import torch.nn.init as init\n","\n","from torch.utils.data import Dataset\n","from PIL import Image\n","import torchvision.transforms as transforms\n","from sklearn.decomposition import PCA\n","\n","import torch\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","\n","from torch import nn\n","from torch import Tensor\n","from PIL import Image\n","from torchvision.transforms import Compose, Resize, ToTensor\n","!pip install einops\n","from einops import rearrange, reduce, repeat\n","from einops.layers.torch import Rearrange, Reduce\n","# from common_spatial_pattern import csp\n","\n","import matplotlib.pyplot as plt\n","# from torch.utils.tensorboard import SummaryWriter\n","from torch.backends import cudnn\n","# cudnn.benchmark = False\n","# cudnn.deterministic = True\n","\n","# writer = SummaryWriter('./TensorBoardX/')\n","\n","\n","# Convolution module\n","# use conv to capture local features, instead of postion embedding.\n","class PatchEmbedding(nn.Module):\n","    def __init__(self, emb_size=40):\n","        # self.patch_size = patch_size\n","        super().__init__()\n","\n","        self.shallownet = nn.Sequential(\n","            nn.Conv2d(1, 40, (1, 25), (1, 1)),\n","            nn.Conv2d(40, 40, (22, 1), (1, 1)),\n","            nn.BatchNorm2d(40),\n","            nn.ELU(),\n","            nn.AvgPool2d((1, 75), (1, 15)),  # pooling acts as slicing to obtain 'patch' along the time dimension as in ViT\n","            nn.Dropout(0.5),\n","        )\n","\n","        self.projection = nn.Sequential(\n","            nn.Conv2d(40, emb_size, (1, 1), stride=(1, 1)),  # transpose, conv could enhance fiting ability slightly\n","            Rearrange('b e (h) (w) -> b (h w) e'),\n","        )\n","\n","\n","    def forward(self, x: Tensor) -> Tensor:\n","        b, _, _, _ = x.shape\n","        x = self.shallownet(x)\n","        x = self.projection(x)\n","        return x\n","\n","\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, emb_size, num_heads, dropout):\n","        super().__init__()\n","        self.emb_size = emb_size\n","        self.num_heads = num_heads\n","        self.keys = nn.Linear(emb_size, emb_size)\n","        self.queries = nn.Linear(emb_size, emb_size)\n","        self.values = nn.Linear(emb_size, emb_size)\n","        self.att_drop = nn.Dropout(dropout)\n","        self.projection = nn.Linear(emb_size, emb_size)\n","\n","    def forward(self, x: Tensor, mask: Tensor = None) -> Tensor:\n","        queries = rearrange(self.queries(x), \"b n (h d) -> b h n d\", h=self.num_heads)\n","        keys = rearrange(self.keys(x), \"b n (h d) -> b h n d\", h=self.num_heads)\n","        values = rearrange(self.values(x), \"b n (h d) -> b h n d\", h=self.num_heads)\n","        energy = torch.einsum('bhqd, bhkd -> bhqk', queries, keys)\n","        if mask is not None:\n","            fill_value = torch.finfo(torch.float32).min\n","            energy.mask_fill(~mask, fill_value)\n","\n","        scaling = self.emb_size ** (1 / 2)\n","        att = F.softmax(energy / scaling, dim=-1)\n","        att = self.att_drop(att)\n","        out = torch.einsum('bhal, bhlv -> bhav ', att, values)\n","        out = rearrange(out, \"b h n d -> b n (h d)\")\n","        out = self.projection(out)\n","        return out\n","\n","\n","class ResidualAdd(nn.Module):\n","    def __init__(self, fn):\n","        super().__init__()\n","        self.fn = fn\n","\n","    def forward(self, x, **kwargs):\n","        res = x\n","        x = self.fn(x, **kwargs)\n","        x += res\n","        return x\n","\n","\n","class FeedForwardBlock(nn.Sequential):\n","    def __init__(self, emb_size, expansion, drop_p):\n","        super().__init__(\n","            nn.Linear(emb_size, expansion * emb_size),\n","            nn.GELU(),\n","            nn.Dropout(drop_p),\n","            nn.Linear(expansion * emb_size, emb_size),\n","        )\n","\n","\n","class GELU(nn.Module):\n","    def forward(self, input: Tensor) -> Tensor:\n","        return input*0.5*(1.0+torch.erf(input/math.sqrt(2.0)))\n","\n","\n","class TransformerEncoderBlock(nn.Sequential):\n","    def __init__(self,\n","                 emb_size,\n","                 num_heads=10,\n","                 drop_p=0.5,\n","                 forward_expansion=4,\n","                 forward_drop_p=0.5):\n","        super().__init__(\n","            ResidualAdd(nn.Sequential(\n","                nn.LayerNorm(emb_size),\n","                MultiHeadAttention(emb_size, num_heads, drop_p),\n","                nn.Dropout(drop_p)\n","            )),\n","            ResidualAdd(nn.Sequential(\n","                nn.LayerNorm(emb_size),\n","                FeedForwardBlock(\n","                    emb_size, expansion=forward_expansion, drop_p=forward_drop_p),\n","                nn.Dropout(drop_p)\n","            )\n","            ))\n","\n","\n","class TransformerEncoder(nn.Sequential):\n","    def __init__(self, depth, emb_size):\n","        super().__init__(*[TransformerEncoderBlock(emb_size) for _ in range(depth)])\n","\n","\n","class ClassificationHead(nn.Sequential):\n","    def __init__(self, emb_size, n_classes, cond_size=128):\n","        super().__init__()\n","\n","        # global average pooling\n","        self.clshead = nn.Sequential(\n","            Reduce('b n e -> b e', reduction='mean'),\n","            nn.LayerNorm(emb_size),\n","            nn.Linear(emb_size, n_classes)\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Linear(12040, 256),\n","            nn.ELU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(256, cond_size),\n","            nn.ELU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(cond_size, 4)\n","        )\n","\n","    def forward(self, x):\n","        # print(x.shape)\n","        x = x.contiguous().view(x.size(0), -1)\n","        # print(x.shape)\n","        out = self.fc(x)\n","        return x, out\n","\n","\n","class Conformer(nn.Sequential):\n","    def __init__(self, emb_size=40, depth=6, n_classes=4, cond_size=128, **kwargs):\n","        super().__init__(\n","\n","            PatchEmbedding(emb_size),\n","            TransformerEncoder(depth, emb_size),\n","            ClassificationHead(emb_size, n_classes, cond_size)\n","        )\n"]},{"cell_type":"code","source":["train_eeg = torch.from_numpy(train_e)\n","train_fmri = torch.from_numpy(train_f)\n","train_l = torch.from_numpy(train_l)\n","\n","test_eeg = torch.from_numpy(test_e)\n","test_fmri = torch.from_numpy(test_f)\n","test_l = torch.from_numpy(test_l)\n"],"metadata":{"id":"LflRoSgtrSXQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KEcdDevRsuJn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701763812944,"user_tz":480,"elapsed":4,"user":{"displayName":"Jiaqi Wu","userId":"00803091932349494936"}},"outputId":"d55486c0-bef3-4253-ee6c-75f2ab677fbd"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2084, 1, 200, 64])\n","torch.Size([32, 4, 2, 12])\n","torch.Size([32, 96])\n"]},{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 1])"]},"metadata":{},"execution_count":41}],"source":["batch_size = 16\n","n_epochs = 2000\n","c_dim = 4\n","lr = 0.0001\n","b1 = 0.5\n","b2 = 0.999\n","train_eeg = torch.permute(train_eeg, (0, 1, 3, 2))\n","test_eeg = torch.permute(test_eeg, (0, 1, 3, 2))\n","print(train_eeg.shape)\n","dataset = torch.utils.data.TensorDataset(train_eeg, train_l)\n","train_dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n","test_dataset = torch.utils.data.TensorDataset(test_eeg, test_l)\n","test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n","\n","start_epoch = 0\n","# root = '/Data/strict_TE/'\n","\n","# log_write = open(\"./results/log_subject%d.txt\" % self.nSub, \"w\")\n","\n","\n","Tensor = torch.cuda.FloatTensor\n","LongTensor = torch.cuda.LongTensor\n","# Tensor = torch.FloatTensor\n","# LongTensor = torch.LongTensor\n","criterion_l1 = torch.nn.L1Loss().cuda()\n","criterion_l2 = torch.nn.MSELoss().cuda()\n","criterion_cls = torch.nn.CrossEntropyLoss().cuda()\n","\n","model = EEGNet().cuda()\n","inps = torch.zeros((32, 1, 200, 64)).cuda()\n","out = model(inps)\n","out.shape\n","# criterion_l1 = torch.nn.L1Loss()\n","# criterion_l2 = torch.nn.MSELoss()\n","# criterion_cls = torch.nn.CrossEntropyLoss()\n","\n","# model = Conformer()\n","# self.model = nn.DataParallel(self.model, device_ids=[i for i in range(len(gpus))])\n","# model = self.model.cuda()\n","\n","# train_e, test_e, train_f, test_f, train_l, test_l = segment_data(dataset_table)\n","# train_e_ = np.expand_dims(np.stack(train_e, axis=0), axis=1)\n","# train_l_ = np.stack(train_l, axis=0)\n","# test_e_ = np.expand_dims(np.stack(test_e, axis=0), axis=1)\n","# test_l_ = np.stack(test_l, axis=0)\n","# print(train_e_.shape)\n","# print(train_l_.shape)\n","# print(test_e_.shape)\n","# print(test_l_.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nOgx5C04suLi"},"outputs":[],"source":["\n","\n","\n","# Optimizers\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr ) #betas=(b1, b2)\n","\n","# test_data = Variable(test_data.cuda().type(Tensor))\n","# test_label = Variable(test_label.cuda().type(LongTensor))\n","\n","device=torch.device('cuda')\n","\n","bestAcc = 0\n","averAcc = 0\n","num = 0\n","Y_true = 0\n","Y_pred = 0\n","\n","# Train the cnn model\n","\n","curr_lr = lr\n","\n","for e in range(n_epochs):\n","    # in_epoch = time.time()\n","    # print(f\"In epoch {e}\")\n","    model.train()\n","    for i, (img, label) in enumerate(train_dataloader):\n","\n","        # img = Variable(img.cuda().type(Tensor))\n","        # label = Variable(label.cuda().type(LongTensor))\n","        img = Variable(img.type(Tensor)).to(device)\n","        label = Variable(label.type(LongTensor)).to(device)\n","        outputs = model(img)\n","\n","        loss = criterion_cls(outputs, label)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","    # test process\n","    if (e + 1) % 10 == 0:\n","        model.eval()\n","        test_acc = 0\n","        count = 0\n","        for i, (img, test_label) in enumerate(test_dataloader):\n","          # img = Variable(img.cuda().type(Tensor))\n","          # label = Variable(label.cuda().type(LongTensor))\n","          img = Variable(img.type(Tensor)).to(device)\n","          test_label = Variable(label.type(LongTensor)).to(device)\n","          Cls = model(img)\n","\n","          loss_test = criterion_cls(Cls, test_label)\n","          y_pred = torch.max(Cls, 1)[1]\n","          acc = float((y_pred == test_label).cpu().numpy().astype(int).sum()) / float(test_label.size(0))\n","          test_acc += acc\n","          count += 1\n","\n","        test_acc = test_acc / count\n","        train_pred = torch.max(outputs, 1)[1]\n","        train_acc = float((train_pred == label).cpu().numpy().astype(int).sum()) / float(label.size(0))\n","\n","        print('Epoch:', e,\n","              '  Train loss: %.6f' % loss.detach().cpu().numpy(), #loss.detach().cpu().numpy()\n","              '  Test loss: %.6f' % loss_test.detach().cpu().numpy(),\n","              '  Train accuracy %.6f' % train_acc,\n","              '  Test accuracy is %.6f' % test_acc)\n","\n","        # self.log_write.write(str(e) + \"    \" + str(acc) + \"\\n\")\n","        num = num + 1\n","        averAcc = averAcc + acc\n","        if acc > bestAcc:\n","            bestAcc = acc\n","            Y_true = test_label\n","            Y_pred = y_pred\n","\n","\n","# torch.save(self.model.module.state_dict(), 'model.pth')\n","averAcc = averAcc / num\n","print('The average accuracy is:', averAcc)\n","print('The best accuracy is:', bestAcc)\n","\n","# return bestAcc, averAcc, Y_true, Y_pred"]},{"cell_type":"code","source":["class EEGNet(nn.Module):\n","    def __init__(self):\n","        super(EEGNet, self).__init__()\n","        self.T = 120\n","\n","        # Layer 1\n","        self.conv1 = nn.Conv2d(1, 16, (1, 64), padding = 0)\n","        self.batchnorm1 = nn.BatchNorm2d(16, False)\n","\n","        # Layer 2\n","        self.padding1 = nn.ZeroPad2d((16, 17, 0, 1))\n","        self.conv2 = nn.Conv2d(1, 4, (2, 32))\n","        self.batchnorm2 = nn.BatchNorm2d(4, False)\n","        self.pooling2 = nn.MaxPool2d(2, 4)\n","\n","        # Layer 3\n","        self.padding2 = nn.ZeroPad2d((2, 1, 4, 3))\n","        self.conv3 = nn.Conv2d(4, 4, (8, 4))\n","        self.batchnorm3 = nn.BatchNorm2d(4, False)\n","        self.pooling3 = nn.MaxPool2d((2, 4))\n","\n","        # FC Layer\n","        # NOTE: This dimension will depend on the number of timestamps per sample in your data.\n","        # I have 120 timepoints.\n","        self.fc1 = nn.Linear(96, 1)\n","\n","\n","    def forward(self, x):\n","        # Layer 1\n","        x = F.elu(self.conv1(x))\n","        x = self.batchnorm1(x)\n","        x = F.dropout(x, 0.25)\n","        x = x.permute(0, 3, 1, 2)\n","\n","        # Layer 2\n","        x = self.padding1(x)\n","        x = F.elu(self.conv2(x))\n","        x = self.batchnorm2(x)\n","        x = F.dropout(x, 0.25)\n","        x = self.pooling2(x)\n","\n","        # Layer 3\n","        x = self.padding2(x)\n","        x = F.elu(self.conv3(x))\n","        x = self.batchnorm3(x)\n","        x = F.dropout(x, 0.25)\n","        x = self.pooling3(x)\n","\n","        # FC Layer\n","        print(x.shape)\n","        x = x.reshape((x.shape[0], -1))\n","        print(x.shape)\n","        x = F.sigmoid(self.fc1(x))\n","        return x"],"metadata":{"id":"uslYTfux-jbj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n"," ARL_EEGModels - A collection of Convolutional Neural Network models for EEG\n"," Signal Processing and Classification, using Keras and Tensorflow\n","\n"," Requirements:\n","    (1) tensorflow == 2.X (as of this writing, 2.0 - 2.3 have been verified\n","        as working)\n","\n"," To run the EEG/MEG ERP classification sample script, you will also need\n","\n","    (4) mne >= 0.17.1\n","    (5) PyRiemann >= 0.2.5\n","    (6) scikit-learn >= 0.20.1\n","    (7) matplotlib >= 2.2.3\n","\n"," To use:\n","\n","    (1) Place this file in the PYTHONPATH variable in your IDE (i.e.: Spyder)\n","    (2) Import the model as\n","\n","        from EEGModels import EEGNet\n","\n","        model = EEGNet(nb_classes = ..., Chans = ..., Samples = ...)\n","\n","    (3) Then compile and fit the model\n","\n","        model.compile(loss = ..., optimizer = ..., metrics = ...)\n","        fitted    = model.fit(...)\n","        predicted = model.predict(...)\n","\n"," Portions of this project are works of the United States Government and are not\n"," subject to domestic copyright protection under 17 USC Sec. 105.  Those\n"," portions are released world-wide under the terms of the Creative Commons Zero\n"," 1.0 (CC0) license.\n","\n"," Other portions of this project are subject to domestic copyright protection\n"," under 17 USC Sec. 105.  Those portions are licensed under the Apache 2.0\n"," license.  The complete text of the license governing this material is in\n"," the file labeled LICENSE.TXT that is a part of this project's official\n"," distribution.\n","\"\"\"\n","\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n","from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.layers import SpatialDropout2D\n","from tensorflow.keras.regularizers import l1_l2\n","from tensorflow.keras.layers import Input, Flatten\n","from tensorflow.keras.constraints import max_norm\n","from tensorflow.keras import backend as K\n","\n","\n","def EEGNet(nb_classes, Chans = 64, Samples = 128,\n","             dropoutRate = 0.5, kernLength = 64, F1 = 8,\n","             D = 2, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout'):\n","    \"\"\" Keras Implementation of EEGNet\n","    http://iopscience.iop.org/article/10.1088/1741-2552/aace8c/meta\n","\n","    Note that this implements the newest version of EEGNet and NOT the earlier\n","    version (version v1 and v2 on arxiv). We strongly recommend using this\n","    architecture as it performs much better and has nicer properties than\n","    our earlier version. For example:\n","\n","        1. Depthwise Convolutions to learn spatial filters within a\n","        temporal convolution. The use of the depth_multiplier option maps\n","        exactly to the number of spatial filters learned within a temporal\n","        filter. This matches the setup of algorithms like FBCSP which learn\n","        spatial filters within each filter in a filter-bank. This also limits\n","        the number of free parameters to fit when compared to a fully-connected\n","        convolution.\n","\n","        2. Separable Convolutions to learn how to optimally combine spatial\n","        filters across temporal bands. Separable Convolutions are Depthwise\n","        Convolutions followed by (1x1) Pointwise Convolutions.\n","\n","\n","    While the original paper used Dropout, we found that SpatialDropout2D\n","    sometimes produced slightly better results for classification of ERP\n","    signals. However, SpatialDropout2D significantly reduced performance\n","    on the Oscillatory dataset (SMR, BCI-IV Dataset 2A). We recommend using\n","    the default Dropout in most cases.\n","\n","    Assumes the input signal is sampled at 128Hz. If you want to use this model\n","    for any other sampling rate you will need to modify the lengths of temporal\n","    kernels and average pooling size in blocks 1 and 2 as needed (double the\n","    kernel lengths for double the sampling rate, etc). Note that we haven't\n","    tested the model performance with this rule so this may not work well.\n","\n","    The model with default parameters gives the EEGNet-8,2 model as discussed\n","    in the paper. This model should do pretty well in general, although it is\n","\tadvised to do some model searching to get optimal performance on your\n","\tparticular dataset.\n","\n","    We set F2 = F1 * D (number of input filters = number of output filters) for\n","    the SeparableConv2D layer. We haven't extensively tested other values of this\n","    parameter (say, F2 < F1 * D for compressed learning, and F2 > F1 * D for\n","    overcomplete). We believe the main parameters to focus on are F1 and D.\n","\n","    Inputs:\n","\n","      nb_classes      : int, number of classes to classify\n","      Chans, Samples  : number of channels and time points in the EEG data\n","      dropoutRate     : dropout fraction\n","      kernLength      : length of temporal convolution in first layer. We found\n","                        that setting this to be half the sampling rate worked\n","                        well in practice. For the SMR dataset in particular\n","                        since the data was high-passed at 4Hz we used a kernel\n","                        length of 32.\n","      F1, F2          : number of temporal filters (F1) and number of pointwise\n","                        filters (F2) to learn. Default: F1 = 8, F2 = F1 * D.\n","      D               : number of spatial filters to learn within each temporal\n","                        convolution. Default: D = 2\n","      dropoutType     : Either SpatialDropout2D or Dropout, passed as a string.\n","\n","    \"\"\"\n","\n","    if dropoutType == 'SpatialDropout2D':\n","        dropoutType = SpatialDropout2D\n","    elif dropoutType == 'Dropout':\n","        dropoutType = Dropout\n","    else:\n","        raise ValueError('dropoutType must be one of SpatialDropout2D '\n","                         'or Dropout, passed as a string.')\n","\n","    input1   = Input(shape = (Chans, Samples, 1))\n","\n","    ##################################################################\n","    block1       = Conv2D(F1, (1, kernLength), padding = 'same',\n","                                   input_shape = (Chans, Samples, 1),\n","                                   use_bias = False)(input1)\n","    block1       = BatchNormalization()(block1)\n","    block1       = DepthwiseConv2D((Chans, 1), use_bias = False,\n","                                   depth_multiplier = D,\n","                                   depthwise_constraint = max_norm(1.))(block1)\n","    block1       = BatchNormalization()(block1)\n","    block1       = Activation('elu')(block1)\n","    block1       = AveragePooling2D((1, 4))(block1)\n","    block1       = dropoutType(dropoutRate)(block1)\n","\n","    block2       = SeparableConv2D(F2, (1, 16),\n","                                   use_bias = False, padding = 'same')(block1)\n","    block2       = BatchNormalization()(block2)\n","    block2       = Activation('elu')(block2)\n","    block2       = AveragePooling2D((1, 8))(block2)\n","    block2       = dropoutType(dropoutRate)(block2)\n","\n","    flatten      = Flatten(name = 'flatten')(block2)\n","\n","    dense        = Dense(nb_classes, name = 'dense',\n","                         kernel_constraint = max_norm(norm_rate))(flatten)\n","    softmax      = Activation('softmax', name = 'softmax')(dense)\n","\n","    return Model(inputs=input1, outputs=softmax)\n","\n","\n","\n","\n","def EEGNet_SSVEP(nb_classes = 12, Chans = 8, Samples = 256,\n","             dropoutRate = 0.5, kernLength = 256, F1 = 96,\n","             D = 1, F2 = 96, dropoutType = 'Dropout'):\n","    \"\"\" SSVEP Variant of EEGNet, as used in [1].\n","\n","    Inputs:\n","\n","      nb_classes      : int, number of classes to classify\n","      Chans, Samples  : number of channels and time points in the EEG data\n","      dropoutRate     : dropout fraction\n","      kernLength      : length of temporal convolution in first layer\n","      F1, F2          : number of temporal filters (F1) and number of pointwise\n","                        filters (F2) to learn.\n","      D               : number of spatial filters to learn within each temporal\n","                        convolution.\n","      dropoutType     : Either SpatialDropout2D or Dropout, passed as a string.\n","\n","\n","    [1]. Waytowich, N. et. al. (2018). Compact Convolutional Neural Networks\n","    for Classification of Asynchronous Steady-State Visual Evoked Potentials.\n","    Journal of Neural Engineering vol. 15(6).\n","    http://iopscience.iop.org/article/10.1088/1741-2552/aae5d8\n","\n","    \"\"\"\n","\n","    if dropoutType == 'SpatialDropout2D':\n","        dropoutType = SpatialDropout2D\n","    elif dropoutType == 'Dropout':\n","        dropoutType = Dropout\n","    else:\n","        raise ValueError('dropoutType must be one of SpatialDropout2D '\n","                         'or Dropout, passed as a string.')\n","\n","    input1   = Input(shape = (Chans, Samples, 1))\n","\n","    ##################################################################\n","    block1       = Conv2D(F1, (1, kernLength), padding = 'same',\n","                                   input_shape = (Chans, Samples, 1),\n","                                   use_bias = False)(input1)\n","    block1       = BatchNormalization()(block1)\n","    block1       = DepthwiseConv2D((Chans, 1), use_bias = False,\n","                                   depth_multiplier = D,\n","                                   depthwise_constraint = max_norm(1.))(block1)\n","    block1       = BatchNormalization()(block1)\n","    block1       = Activation('elu')(block1)\n","    block1       = AveragePooling2D((1, 4))(block1)\n","    block1       = dropoutType(dropoutRate)(block1)\n","\n","    block2       = SeparableConv2D(F2, (1, 16),\n","                                   use_bias = False, padding = 'same')(block1)\n","    block2       = BatchNormalization()(block2)\n","    block2       = Activation('elu')(block2)\n","    block2       = AveragePooling2D((1, 8))(block2)\n","    block2       = dropoutType(dropoutRate)(block2)\n","\n","    flatten      = Flatten(name = 'flatten')(block2)\n","\n","    dense        = Dense(nb_classes, name = 'dense')(flatten)\n","    softmax      = Activation('softmax', name = 'softmax')(dense)\n","\n","    return Model(inputs=input1, outputs=softmax)\n","\n","\n","\n","def EEGNet_old(nb_classes, Chans = 64, Samples = 128, regRate = 0.0001,\n","           dropoutRate = 0.25, kernels = [(2, 32), (8, 4)], strides = (2, 4)):\n","    \"\"\" Keras Implementation of EEGNet_v1 (https://arxiv.org/abs/1611.08024v2)\n","\n","    This model is the original EEGNet model proposed on arxiv\n","            https://arxiv.org/abs/1611.08024v2\n","\n","    with a few modifications: we use striding instead of max-pooling as this\n","    helped slightly in classification performance while also providing a\n","    computational speed-up.\n","\n","    Note that we no longer recommend the use of this architecture, as the new\n","    version of EEGNet performs much better overall and has nicer properties.\n","\n","    Inputs:\n","\n","        nb_classes     : total number of final categories\n","        Chans, Samples : number of EEG channels and samples, respectively\n","        regRate        : regularization rate for L1 and L2 regularizations\n","        dropoutRate    : dropout fraction\n","        kernels        : the 2nd and 3rd layer kernel dimensions (default is\n","                         the [2, 32] x [8, 4] configuration)\n","        strides        : the stride size (note that this replaces the max-pool\n","                         used in the original paper)\n","\n","    \"\"\"\n","\n","    # start the model\n","    input_main   = Input((Chans, Samples))\n","    layer1       = Conv2D(16, (Chans, 1), input_shape=(Chans, Samples, 1),\n","                                 kernel_regularizer = l1_l2(l1=regRate, l2=regRate))(input_main)\n","    layer1       = BatchNormalization()(layer1)\n","    layer1       = Activation('elu')(layer1)\n","    layer1       = Dropout(dropoutRate)(layer1)\n","\n","    permute_dims = 2, 1, 3\n","    permute1     = Permute(permute_dims)(layer1)\n","\n","    layer2       = Conv2D(4, kernels[0], padding = 'same',\n","                            kernel_regularizer=l1_l2(l1=0.0, l2=regRate),\n","                            strides = strides)(permute1)\n","    layer2       = BatchNormalization()(layer2)\n","    layer2       = Activation('elu')(layer2)\n","    layer2       = Dropout(dropoutRate)(layer2)\n","\n","    layer3       = Conv2D(4, kernels[1], padding = 'same',\n","                            kernel_regularizer=l1_l2(l1=0.0, l2=regRate),\n","                            strides = strides)(layer2)\n","    layer3       = BatchNormalization()(layer3)\n","    layer3       = Activation('elu')(layer3)\n","    layer3       = Dropout(dropoutRate)(layer3)\n","\n","    flatten      = Flatten(name = 'flatten')(layer3)\n","\n","    dense        = Dense(nb_classes, name = 'dense')(flatten)\n","    softmax      = Activation('softmax', name = 'softmax')(dense)\n","\n","    return Model(inputs=input_main, outputs=softmax)\n","\n","\n","\n","def DeepConvNet(nb_classes, Chans = 64, Samples = 256,\n","                dropoutRate = 0.5):\n","    \"\"\" Keras implementation of the Deep Convolutional Network as described in\n","    Schirrmeister et. al. (2017), Human Brain Mapping.\n","\n","    This implementation assumes the input is a 2-second EEG signal sampled at\n","    128Hz, as opposed to signals sampled at 250Hz as described in the original\n","    paper. We also perform temporal convolutions of length (1, 5) as opposed\n","    to (1, 10) due to this sampling rate difference.\n","\n","    Note that we use the max_norm constraint on all convolutional layers, as\n","    well as the classification layer. We also change the defaults for the\n","    BatchNormalization layer. We used this based on a personal communication\n","    with the original authors.\n","\n","                      ours        original paper\n","    pool_size        1, 2        1, 3\n","    strides          1, 2        1, 3\n","    conv filters     1, 5        1, 10\n","\n","    Note that this implementation has not been verified by the original\n","    authors.\n","\n","    \"\"\"\n","\n","    # start the model\n","    input_main   = Input((Chans, Samples, 1))\n","    block1       = Conv2D(25, (1, 5),\n","                                 input_shape=(Chans, Samples, 1),\n","                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(input_main)\n","    block1       = Conv2D(25, (Chans, 1),\n","                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n","    block1       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block1)\n","    block1       = Activation('elu')(block1)\n","    block1       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block1)\n","    block1       = Dropout(dropoutRate)(block1)\n","\n","    block2       = Conv2D(50, (1, 5),\n","                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n","    block2       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block2)\n","    block2       = Activation('elu')(block2)\n","    block2       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block2)\n","    block2       = Dropout(dropoutRate)(block2)\n","\n","    block3       = Conv2D(100, (1, 5),\n","                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block2)\n","    block3       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block3)\n","    block3       = Activation('elu')(block3)\n","    block3       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block3)\n","    block3       = Dropout(dropoutRate)(block3)\n","\n","    block4       = Conv2D(200, (1, 5),\n","                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block3)\n","    block4       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block4)\n","    block4       = Activation('elu')(block4)\n","    block4       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block4)\n","    block4       = Dropout(dropoutRate)(block4)\n","\n","    flatten      = Flatten()(block4)\n","\n","    dense        = Dense(nb_classes, kernel_constraint = max_norm(0.5))(flatten)\n","    softmax      = Activation('softmax')(dense)\n","\n","    return Model(inputs=input_main, outputs=softmax)\n","\n","\n","# need these for ShallowConvNet\n","def square(x):\n","    return K.square(x)\n","\n","def log(x):\n","    return K.log(K.clip(x, min_value = 1e-7, max_value = 10000))\n","\n","\n","def ShallowConvNet(nb_classes, Chans = 64, Samples = 128, dropoutRate = 0.5):\n","    \"\"\" Keras implementation of the Shallow Convolutional Network as described\n","    in Schirrmeister et. al. (2017), Human Brain Mapping.\n","\n","    Assumes the input is a 2-second EEG signal sampled at 128Hz. Note that in\n","    the original paper, they do temporal convolutions of length 25 for EEG\n","    data sampled at 250Hz. We instead use length 13 since the sampling rate is\n","    roughly half of the 250Hz which the paper used. The pool_size and stride\n","    in later layers is also approximately half of what is used in the paper.\n","\n","    Note that we use the max_norm constraint on all convolutional layers, as\n","    well as the classification layer. We also change the defaults for the\n","    BatchNormalization layer. We used this based on a personal communication\n","    with the original authors.\n","\n","                     ours        original paper\n","    pool_size        1, 35       1, 75\n","    strides          1, 7        1, 15\n","    conv filters     1, 13       1, 25\n","\n","    Note that this implementation has not been verified by the original\n","    authors. We do note that this implementation reproduces the results in the\n","    original paper with minor deviations.\n","    \"\"\"\n","\n","    # start the model\n","    input_main   = Input((Chans, Samples, 1))\n","    block1       = Conv2D(40, (1, 13),\n","                                 input_shape=(Chans, Samples, 1),\n","                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(input_main)\n","    block1       = Conv2D(40, (Chans, 1), use_bias=False,\n","                          kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n","    block1       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block1)\n","    block1       = Activation(square)(block1)\n","    block1       = AveragePooling2D(pool_size=(1, 35), strides=(1, 7))(block1)\n","    block1       = Activation(log)(block1)\n","    block1       = Dropout(dropoutRate)(block1)\n","    flatten      = Flatten()(block1)\n","    dense        = Dense(nb_classes, kernel_constraint = max_norm(0.5))(flatten)\n","    softmax      = Activation('softmax')(dense)\n","\n","    return Model(inputs=input_main, outputs=softmax)"],"metadata":{"id":"7i_wCX9i8isk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model  = EEGNet(nb_classes=4, Chans=64, Samples=200)\n","AUTOTUNE = tf.data.experimental.AUTOTUNE\n","model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n","ds = tf.dattrain_dataset = tf.data.Dataset.from_tensor_slices((train_e, train_y))\n","train_dataset = train_dataset.shuffle(buffer_size=1000, reshuffle_each_iteration=True)\n","train_dataset = train_dataset.batch(batch_size).prefetch(AUTOTUNE)\n","\n","test_dataset = tf.data.Dataset.from_tensor_slices((test_e, test_y))\n","test_dataset = test_dataset.batch(batch_size).prefetch(AUTOTUNE)\n","fittedModel = model.fit(...)\n","predicted = model.predict(...)"],"metadata":{"id":"D5SY2Yzv8v3B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Con-VAE With ELBO & NIWAE"],"metadata":{"id":"LARishiE2Ssp"}},{"cell_type":"code","source":["\n","import torch\n","from torch import nn\n","from torch.nn import functional as F\n","\n","\n","def log_mean_exp(x, dim):\n","    \"\"\"\n","    Compute the log(mean(exp(x), dim)) in a numerically stable manner\n","\n","    Args:\n","        x: tensor: (...): Arbitrary tensor\n","        dim: int: (): Dimension along which mean is computed\n","\n","    Return:\n","        _: tensor: (...): log(mean(exp(x), dim))\n","    \"\"\"\n","    return log_sum_exp(x, dim) - np.log(x.size(dim))\n","\n","\n","def log_sum_exp(x, dim=0):\n","    \"\"\"\n","    Compute the log(sum(exp(x), dim)) in a numerically stable manner\n","\n","    Args:\n","        x: tensor: (...): Arbitrary tensor\n","        dim: int: (): Dimension along which sum is computed\n","\n","    Return:\n","        _: tensor: (...): log(sum(exp(x), dim))\n","    \"\"\"\n","    max_x = torch.max(x, dim)[0]\n","    new_x = x - max_x.unsqueeze(dim).expand_as(x)\n","    return max_x + (new_x.exp().sum(dim)).log()\n","\n","def log_normal(x, m, v):\n","    \"\"\"\n","    Computes the elem-wise log probability of a Gaussian and then sum over the\n","    last dim. Basically we're assuming all dims are batch dims except for the\n","    last dim.\n","\n","    Args:\n","        x: tensor: (batch_1, batch_2, ..., batch_k, dim): Observation\n","        m: tensor: (batch_1, batch_2, ..., batch_k, dim): Mean\n","        v: tensor: (batch_1, batch_2, ..., batch_k, dim): Variance\n","\n","    Return:\n","        log_prob: tensor: (batch_1, batch_2, ..., batch_k): log probability of\n","            each sample. Note that the summation dimension is not kept\n","    \"\"\"\n","    ################################################################################\n","    # TODO: Modify/complete the code here\n","    # Compute element-wise log probability of normal and remember to sum over\n","    # the last dimension\n","    ################################################################################\n","    # assert x.shape == m.shape\n","    log_prob = -0.5 * torch.sum(torch.log(torch.Tensor([2.0]).cuda() * torch.pi) + torch.log(v) + torch.pow(x - m, 2) / v, dim=-1)\n","\n","    ################################################################################\n","    # End of code modification\n","    ################################################################################\n","    return log_prob\n","\n","\n","\n","def log_normal_mixture(z, m, v):\n","    \"\"\"\n","    Computes log probability of Gaussian mixture.\n","\n","    Args:\n","        z: tensor: (batch, dim): Observations\n","        m: tensor: (batch, mix, dim): Mixture means\n","        v: tensor: (batch, mix, dim): Mixture variances\n","\n","    Return:\n","        log_prob: tensor: (batch,): log probability of each sample\n","    \"\"\"\n","    ################################################################################\n","    # TODO: Modify/complete the code here\n","    # Compute the uniformly-weighted mixture of Gaussians density for each sample\n","    # in the batch\n","    ################################################################################\n","    b, k, d = m.shape\n","    # print(m.shape)\n","    # print(z.shape)\n","    # print(m.shape)\n","    z = torch.unsqueeze(z, dim=1)\n","    # assert z.shape == m.shape\n","    log_prob = log_normal(z, m, v)\n","    log_prob = log_mean_exp(log_prob, dim=1)\n","    # log_prob = torch.log(1/k * torch.sum(s, dim=-1))\n","    ################################################################################\n","    # End of code modification\n","    ################################################################################\n","    # print(log_prob.shape)\n","    # assert log_prob.shape == (m.shape[0],)\n","    return log_prob\n","\n","\n","def gaussian_parameters(h, dim=-1):\n","    \"\"\"\n","    Converts generic real-valued representations into mean and variance\n","    parameters of a Gaussian distribution\n","\n","    Args:\n","        h: tensor: (batch, ..., dim, ...): Arbitrary tensor\n","        dim: int: (): Dimension along which to split the tensor for mean and\n","            variance\n","\n","    Returns:\n","        m: tensor: (batch, ..., dim / 2, ...): Mean\n","        v: tensor: (batch, ..., dim / 2, ...): Variance\n","    \"\"\"\n","    m, h = torch.split(h, h.size(dim) // 2, dim=dim)\n","    v = F.softplus(h) + 1e-8\n","    return m, v\n","\n","bce = torch.nn.BCEWithLogitsLoss(reduction='none')\n","\n","def log_bernoulli_with_logits(x, logits):\n","    \"\"\"\n","    Computes the log probability of a Bernoulli given its logits\n","\n","    Args:\n","        x: tensor: (batch, dim): Observation\n","        logits: tensor: (batch, dim): Bernoulli logits\n","\n","    Return:\n","        log_prob: tensor: (batch,): log probability of each sample\n","    \"\"\"\n","    log_prob = -bce(input=logits, target=x).mean((1, 2, 3, 4))\n","    return log_prob\n","\n","def sample_gaussian(m, v):\n","    \"\"\"\n","    Element-wise application reparameterization trick to sample from Gaussian\n","\n","    Args:\n","        m: tensor: (batch, ...): Mean\n","        v: tensor: (batch, ...): Variance\n","\n","    Return:\n","        z: tensor: (batch, dim): Samples\n","    \"\"\"\n","    ################################################################################\n","    # TODO: Modify/complete the code here\n","    # Sample z\n","    ################################################################################\n","    eps = torch.randn_like(v).cuda()\n","    z = m + torch.sqrt(v) * eps\n","    ################################################################################\n","    # End of code modification\n","    ################################################################################\n","    return z\n","\n","def duplicate(x, rep):\n","    \"\"\"\n","    Duplicates x along dim=0\n","\n","    Args:\n","        x: tensor: (batch, ...): Arbitrary tensor\n","        rep: int: (): Number of replicates. Setting rep=1 returns orignal x\n","\n","    Returns:\n","        _: tensor: (batch * rep, ...): Arbitrary replicated tensor\n","    \"\"\"\n","    return x.expand(rep, *x.shape).reshape(-1, *x.shape[1:])\n","\n","class CVAE3D(nn.Module):\n","    def __init__(self, feature_size=256, latent_size=128, conditional_size=4, hidden_size=400, k=10, z_dim=2, iw=10):\n","        super(CVAE3D, self).__init__()\n","         # Mixture of Gaussians prior\n","        self.k = k\n","        self.z_dim = z_dim\n","        self.iw = iw\n","\n","        self.z_pre = torch.nn.Parameter(torch.randn(1, 2 * self.k, self.z_dim)\n","                                        / np.sqrt(self.k * self.z_dim))\n","        # Uniform weighting\n","        self.pi = torch.nn.Parameter(torch.ones(k) / k, requires_grad=False)\n","\n","        self.feature_size = feature_size\n","        self.conditional_size = conditional_size\n","\n","        # self.eeg_model = Conformer(cond_size=conditional_size)\n","\n","        # encode\n","        # input size: batch, 1, 16, 64, 64\n","        self.conv1  = nn.Conv3d(1, 16, kernel_size=3, stride=(2, 2, 2), padding=1) # , 16, 32, 32\n","        self.enc_bn1 = nn.BatchNorm3d(16)\n","        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, stride=(2, 2, 2), padding=1) # 8, 16, 16\n","        self.enc_bn2 = nn.BatchNorm3d(32)\n","        self.conv3 = nn.Conv3d(32, 16, kernel_size=3, stride=(2, 2, 2), padding=1) #4, 8, 8\n","        self.enc_bn3 = nn.BatchNorm3d(16)\n","        self.conv4 = nn.Conv3d(16, 1, kernel_size=3, stride=1, padding=1) # 4, 8, 8\n","        self.flat = nn.Flatten()\n","        # ---- End of encoder feature extraction -----\n","\n","        # fc to z-dim\n","        self.fc11 = nn.Linear(256 + conditional_size, 2 * self.z_dim)\n","        # self.fc12 = nn.Linear(64 + conditional_size, self.z_dim)\n","\n","        # decoder, conv3d + upsample\n","        # latent to a linear [4, 4, 4]\n","        self.d_fc = nn.Linear(self.z_dim + conditional_size, 2*4*4*8)\n","        # self.transpose_3d = nn.ConvTranspose3d(8, 32, kernel_size=3, stride=2, padding=1, bias=True)\n","        self.tp_conv1 = nn.Conv3d(8, 32, kernel_size=3, stride=1, padding=1, bias=True)\n","        self.dec_bn1 = nn.BatchNorm3d(32)\n","        self.tp_conv2 = nn.Conv3d(32, 64, kernel_size=3, stride=1, padding=1, bias=True)\n","        self.dec_bn2 = nn.BatchNorm3d(64)\n","        self.tp_conv3 = nn.Conv3d(64, 32, kernel_size=3, stride=1, padding=1, bias=True)\n","        self.dec_bn3 = nn.BatchNorm3d(32)\n","        self.tp_conv4 = nn.Conv3d(32, 1, kernel_size=3, stride=1, padding=1, bias=True)\n","\n","        self.sigmoid = nn.Sigmoid()\n","        # self.tanh = F.tanh()\n","\n","    def encode(self, x, condition): # Q(z|x, c) condition:(batch, conditional_size); x: (batch, 104, 106, 16)\n","        '''\n","        x dimension: (batch_size, channel, depth, height, width)\n","        c dimension: (batch_size, feature_size)\n","        '''\n","        # inputs = torch.cat([x, condition], 1) # (bs, feature_size+class_size)\n","        # h1 = self.elu(self.fc1(inputs))\n","        # _, condition = self.eeg_model(eeg_input)\n","        x1 = F.leaky_relu(self.enc_bn1(self.conv1(x)))\n","        # print(x1.shape)\n","        x2 = F.leaky_relu(self.enc_bn2(self.conv2(x1)))\n","        # print(x2.shape)\n","        x3 = F.leaky_relu(self.enc_bn3(self.conv3(x2)))\n","        x4 = self.conv4(x3)\n","        flat = self.flat(x4)\n","        # print(flat.shape)\n","        # print(flat.shape)\n","        conditioned = torch.concat([flat, condition], dim=-1)\n","        # print(conditioned.shape)\n","\n","        z_m_v = self.fc11(conditioned)\n","        # z_var = self.fc12(conditioned)\n","        z_mu, z_var = gaussian_parameters(z_m_v, dim=-1)\n","        # print(\" checking z_mu and z_var\")\n","        # print(z_mu, z_var)\n","        return z_mu, z_var\n","\n","    # def gaussian_sample(self, mu, logvar):\n","    #     std = torch.exp(0.5*logvar)\n","    #     eps = torch.randn_like(std)\n","    #     return mu + eps*std\n","\n","    def negative_elbo_bound(self, fmri, label):\n","        \"\"\"\n","        Computes the Evidence Lower Bound, KL and, Reconstruction costs\n","\n","        Args:\n","            x: tensor: (batch, dim): Observations\n","\n","        Returns:\n","            nelbo: tensor: (): Negative evidence lower bound\n","            kl: tensor: (): ELBO KL divergence to prior\n","            rec: tensor: (): ELBO Reconstruction term\n","        \"\"\"\n","        ################################################################################\n","        # TODO: Modify/complete the code here\n","        # Compute negative Evidence Lower Bound and its KL and Rec decomposition\n","        #\n","        # To help you start, we have computed the mixture of Gaussians prior\n","        # prior = (m_mixture, v_mixture) for you, where\n","        # m_mixture and v_mixture each have shape (1, self.k, self.z_dim)\n","        #\n","        # Note that nelbo = kl + rec\n","        #\n","        # Outputs should all be scalar\n","        ################################################################################\n","        # We provide the learnable prior for you. Familiarize yourself with\n","        # this object by checking its shape.\n","        batch = fmri.shape[0]\n","        prior = gaussian_parameters(self.z_pre, dim=1)\n","        m, v = self.encode(fmri, label) # mu & v\n","        # print(\" checking m and v:\")\n","        # print(m, v)\n","        assert not torch.isnan(m).any()\n","        assert not torch.isnan(v).any()\n","        # print(\"m shape: \", m.shape)\n","        # print(\"v shape: \", v.shape)\n","\n","        z = sample_gaussian(m, v) # q(z|x)\n","        # print(\" checking z: \")\n","        # print(z)\n","\n","        a = log_normal(z, m, v)\n","        # print(a)\n","\n","        b = log_normal_mixture(z, *prior)\n","        # print(b)\n","\n","        kl = a - b\n","        assert kl.shape[0] == fmri.shape[0]\n","        # x_reconstructed = self.sample_x_given(z) # p(x | z) z~q(z|x)\n","        logits = self.decode(z, label)\n","        rec = log_bernoulli_with_logits(fmri, logits) * (-1)\n","        # print(\"rec loss shape: \", rec.shape)\n","        nelbo = kl + rec\n","        kl = kl.mean()\n","        rec = rec.mean()\n","        nelbo = nelbo.mean()\n","        # print(nelbo, kl, rec)\n","\n","        ################################################################################\n","        # End of code modification\n","        ################################################################################\n","        return nelbo, kl, rec\n","\n","\n","    def negative_iwae_bound(self, x, label):\n","        \"\"\"\n","        Computes the Importance Weighted Autoencoder Bound\n","        Additionally, we also compute the ELBO KL and reconstruction terms\n","\n","        Args:\n","            x: tensor: (batch, dim): Observations\n","            iw: int: (): Number of importance weighted samples\n","\n","        Returns:\n","            niwae: tensor: (): Negative IWAE bound\n","            kl: tensor: (): ELBO KL divergence to prior\n","            rec: tensor: (): ELBO Reconstruction term\n","        \"\"\"\n","        ################################################################################\n","        # TODO: Modify/complete the code here\n","        # Compute niwae (negative IWAE) with iw importance samples, and the KL\n","        # and Rec decomposition of the Evidence Lower Bound\n","        #\n","        # Outputs should all be scalar\n","        ################################################################################\n","        # We provide the learnable prior for you. Familiarize yourself with\n","        # this object by checking its shape.\n","        iw = self.iw\n","        prior = gaussian_parameters(self.z_pre, dim=1)\n","        m, v = self.encode(x, label)\n","        m = duplicate(m, iw)\n","        v = duplicate(v, iw)\n","        x = duplicate(x, iw)\n","        label = duplicate(label, iw)\n","        z = sample_gaussian(m, v)\n","        logits = self.decode(z, label)\n","        kl = log_normal(z, m, v) - log_normal_mixture(z, *prior)\n","        rec = -log_bernoulli_with_logits(x, logits)\n","        nelbo = kl + rec\n","        niwae = -log_mean_exp(-nelbo.reshape(iw, -1), dim=0)\n","        niwae = niwae.mean()\n","        kl = kl.mean()\n","        rec = rec.mean()\n","        ################################################################################\n","        # End of code modification\n","        ################################################################################\n","        return niwae, kl, rec\n","\n","    def loss(self, fmri, label):\n","        nelbo, kl, rec = self.negative_nelbo_bound(fmri, label)\n","        loss = nelbo\n","\n","        summaries = dict((\n","            ('train/loss', nelbo),\n","            ('gen/elbo', -nelbo),\n","            ('gen/kl_z', kl),\n","            ('gen/rec', rec),\n","        ))\n","\n","        return loss, summaries\n","\n","    def decode(self, z, c): # P(x|z, c)\n","        '''\n","        z: (bs, latent_size)\n","        c: (bs, class_size)\n","        '''\n","        # print(\"In decode\")\n","        # print(z.shape, c.shape)\n","        conditioned_noise = torch.cat([z, c], 1) # (bs, latent_size+conditional_size)\n","        res = self.d_fc(conditioned_noise)\n","        res = torch.reshape(res, (-1, 8, 2, 4, 4))\n","        res = nn.ReLU()(self.dec_bn1(self.tp_conv1(res))) # batch, 32, 4, 4, 4\n","        # print(res.shape)\n","        res = F.interpolate(res, scale_factor=2) # batch, 32, 8, 8, 8\n","        # print(res.shape)\n","        assert res.shape[1:] == (32, 4, 8, 8)\n","\n","        res = nn.ReLU()(self.dec_bn2(self.tp_conv2(res))) # batch, 64, 8, 8, 8\n","        res = F.interpolate(res, scale_factor=2) # batch, 64, 16, 16, 16\n","        assert res.shape[1:] == (64, 8, 16, 16)\n","\n","        res = nn.ReLU()(self.dec_bn3(self.tp_conv3(res))) # batch, 32, 16, 16, 16\n","        res = F.interpolate(res, scale_factor=2) # batch, 32, 16, 32, 32\n","        assert res.shape[1:] == (32, 16, 32, 32)\n","\n","        res = nn.ReLU()(self.tp_conv4(res)) # batch, 1, 32, 32, 32\n","        res = F.interpolate(res, scale_factor=(2, 2, 2)) # batch, 1, 16, 64, 64\n","        assert res.shape[1:] == (1, 32, 64, 64)\n","\n","        # res = self.sigmoid(res)\n","        res = F.tanh(res)\n","\n","        return res\n","\n","    # def forward(self, x, condition):\n","    #     mu, logvar = self.encode(x, condition)\n","    #     z = self.gaussian_sample(mu, logvar)\n","    #     dec = self.decode(z, condition)\n","    #     return dec, mu, logvar\n","\n"],"metadata":{"id":"o2txBtUq2Rvq"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Utu04PMfm4J1"},"outputs":[],"source":["input = torch.zeros((1, 1, 16, 64, 64))\n","c = torch.ones((1, 1, 64, 200))\n","l = torch.ones((1, 4))\n","model = CVAE3D()\n","loss, summary = model.loss(input, l)\n","loss"]},{"cell_type":"code","source":["batch_size=16\n","\n","dataset = torch.utils.data.TensorDataset(train_fmri, train_l)\n","train_dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n","test_dataset = torch.utils.data.TensorDataset(test_fmri, test_l)\n","test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n"],"metadata":{"id":"Jm0TollrZZq3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tlVTXglIlCbz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tqdm\n","BCE_loss = nn.BCELoss(reduction = \"sum\")\n","\n","def loss(X, X_hat, mean, logvar):\n","    KLD = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())\n","        #reconstruction\n","    # print(X_hat.min(), X_hat.max(), X.min(), X.max())\n","\n","    REC = BCE_loss(X_hat, X)\n","    # print(KLD+REC)\n","    return KLD + REC\n","\n","\n","device = torch.device('cuda')\n","\n","cond_size = 4\n","z_dim = 8\n","k = 10\n","\n","net = CVAE3D(conditional_size=cond_size, k=k, z_dim=z_dim).to(device)\n","# eeg_extractor = Conformer(cond_size=cond_size).to(device)\n","\n","\n","############### training #########################\n","\n","lr = 0.0001\n","optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n","\n","def adjust_lr(optimizer, decay_rate=0.95):\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] *= decay_rate\n","\n","retrain = True\n","\n","max_epochs = 10000\n","\n","def one_hot(labels, class_size, device):\n","    targets = torch.zeros(labels.size(0), class_size)\n","    for i, label in enumerate(labels):\n","        targets[i, label] = 1\n","    return targets.to(device)\n","\n","print(\"training on \", device)\n","train_losses = []\n","val_losses = []\n","samples_class_0 = []\n","samples_class_1 = []\n","samples_class_2 = []\n","samples_class_3 = []\n","for epoch in range(max_epochs):\n","    train_loss, n, start = 0.0, 0, time.time()\n","    net.train()\n","    for fmri, label in tqdm.tqdm(train_dataloader, ncols = 50):\n","        # print(eeg.shape, fmri.shape)\n","        # for i in range(batch_size):\n","        #   plt.imshow(fmri[i][0][5], cmap='gray')\n","        #   plt.show()\n","        fmri = fmri.type(torch.float32).to(device)\n","        # eeg = eeg.type(torch.float32).to(device)\n","        # _, eeg_f = eeg_extractor(eeg)\n","        # print(eeg.shape)\n","        labels = one_hot(label, 4, device)\n","        # X_hat, mean, logvar = net(fmri, labels)\n","        l, summaries = net.loss(fmri, labels)\n","\n","        # l = loss(fmri, X_hat, mean, logvar).to(device)\n","        optimizer.zero_grad()\n","        # print(\"Backward propagating..\")\n","        # print(l)\n","        l.backward()\n","        optimizer.step()\n","\n","        train_loss += l.cpu().item()\n","        n += fmri.shape[0]\n","\n","    train_loss /= n\n","    train_losses.append(train_loss)\n","    print('epoch %d, train loss %.4f , time %.1f sec'\n","          % (epoch, train_loss, time.time() - start))\n","\n","    # adjust_lr(optimizer)\n","\n","    if (epoch+1) % 2 == 0:\n","      val_loss = 0.0\n","      count = 0\n","      net.eval()\n","      for fmri, label in tqdm.tqdm(test_dataloader, ncols=50):\n","        fmri = fmri.type(torch.float32).to(device)\n","        # eeg = eeg.type(torch.float32).to(device)\n","        # _, eeg_f = eeg_extractor(eeg)\n","        # print(eeg.shape)\n","        labels = one_hot(label, 4, device)\n","        # X_hat, mean, logvar = net(fmri, labels)\n","        l, summaries = net.loss(fmri, labels)\n","\n","        # l = loss(fmri, X_hat, mean, logvar).to(device)\n","        val_loss += l.cpu().item()\n","        count += fmri.shape[0]\n","      val_loss /= n\n","      val_losses.append(val_loss)\n","      print(f\"validation loss: {val_loss}\")\n","\n","      noise = torch.randn((4, z_dim)).cuda()\n","      label = torch.Tensor([[0], [1], [2], [3]]).long().cuda()\n","      cond = one_hot(label, 4, device)\n","      net.eval()\n","      with torch.no_grad():\n","        sample = net.decode(noise, cond).cpu().numpy()\n","        print(sample.shape)\n","        samples_class_0.append(sample[0][0])\n","        samples_class_1.append(sample[1][0])\n","        samples_class_2.append(sample[2][0])\n","        samples_class_3.append(sample[3][0])\n","\n"],"metadata":{"id":"VW3NkbkR78n8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"aa222401-935f-4ffe-d56d-43d6b762be24"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["training on  cuda\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0, train loss 0.0444 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 1, train loss 0.0440 , time 9.2 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.005053565393273647\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 2, train loss 0.0437 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 3, train loss 0.0437 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 32.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.004967969971207472\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 4, train loss 0.0438 , time 9.0 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 5, train loss 0.0436 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 35.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.005071812409621019\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 6, train loss 0.0436 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 7, train loss 0.0437 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.005029282346367836\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 8, train loss 0.0436 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 9, train loss 0.0435 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 35.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.004975768637198668\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 10, train loss 0.0436 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 11, train loss 0.0436 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 33.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.005074183700176386\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 12, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 13, train loss 0.0437 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.005031582140005552\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 14, train loss 0.0435 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 15, train loss 0.0437 , time 9.0 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 35.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.005020864565785115\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 16, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 17, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 33.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.0049513666962201774\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 18, train loss 0.0436 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 19, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.0050385057066495605\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 20, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 21, train loss 0.0435 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.005025372081078016\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 22, train loss 0.0435 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 23, train loss 0.0436 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.004997239061273061\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 24, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 25, train loss 0.0435 , time 9.2 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.004971594821948272\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 26, train loss 0.0435 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 27, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.005028224306610914\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 28, train loss 0.0435 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 29, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.0050035166625793165\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 30, train loss 0.0435 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 31, train loss 0.0435 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 35.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.0050225359889177175\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 32, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 33, train loss 0.0435 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 33.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.00502888156244388\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 34, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 35, train loss 0.0434 , time 9.2 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 33.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.0050007247007810155\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 36, train loss 0.0433 , time 9.2 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 37, train loss 0.0435 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 33.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.005004547278468425\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 38, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 39, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 35.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.004961446500741518\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 40, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 41, train loss 0.0434 , time 9.0 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 33.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.004989257483528211\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 42, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 43, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 33.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.005033118965534064\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 44, train loss 0.0435 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 45, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.005014975512256989\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 46, train loss 0.0432 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 47, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.00498935987169926\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 48, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 49, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.0049334892286704134\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 50, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 51, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.0049993851150457675\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 52, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 53, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.0049842339868728935\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 54, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 55, train loss 0.0431 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.72it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.005051378877117083\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 56, train loss 0.0435 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 57, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.005012735609824841\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 58, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 59, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.0049912173874103105\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 60, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 61, train loss 0.0432 , time 9.2 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.0050398988792529475\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 62, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 63, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.005018151408204666\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 64, train loss 0.0433 , time 9.2 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 65, train loss 0.0435 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.00500501342690908\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 66, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 67, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 33.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.004987489059567451\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 68, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 69, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.0049962760737309085\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 70, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 71, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 33.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.00501796414072697\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 72, train loss 0.0432 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 73, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.005040060098354633\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 74, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 75, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.005023034461415731\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 76, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 77, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.005000239295455126\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 78, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 79, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.004969426101216903\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 80, train loss 0.0434 , time 9.2 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 81, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.0050266428062549\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 82, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 83, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.004995354981376574\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 84, train loss 0.0435 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 85, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 35.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.005006902922804539\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 86, train loss 0.0434 , time 9.0 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 87, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.005013325638495959\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 88, train loss 0.0433 , time 9.2 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 89, train loss 0.0435 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 33.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.004968508648184629\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 90, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 91, train loss 0.0433 , time 9.2 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.005017001296465214\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 92, train loss 0.0434 , time 9.2 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 93, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.004983637052086683\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 94, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 95, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.005014449816483718\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 96, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 97, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 33.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.0050395589608412525\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 98, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 99, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.004956504444663341\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 100, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 101, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.005016816235505618\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 102, train loss 0.0433 , time 9.2 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 103, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.00500537993816229\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 104, train loss 0.0432 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 105, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.004986695314829166\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 106, train loss 0.0432 , time 9.2 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 13.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 107, train loss 0.0435 , time 9.4 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 33.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.004982014659505624\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 108, train loss 0.0433 , time 9.2 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 109, train loss 0.0434 , time 9.2 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 33.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.005014997949967018\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 110, train loss 0.0434 , time 9.2 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 111, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 35.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.004968976315397482\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 112, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 113, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 34.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.004989002559047479\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 114, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 115, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 33.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.005025259720591398\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 116, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 117, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 33.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.005005207027380283\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 118, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 119, train loss 0.0433 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████| 15/15 [00:00<00:00, 33.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["validation loss: 0.005024027681121459\n","(4, 1, 32, 64, 64)\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████| 130/130 [00:09<00:00, 14.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch 120, train loss 0.0434 , time 9.1 sec\n"]},{"output_type":"stream","name":"stderr","text":[" 21%|██▍         | 27/130 [00:01<00:07, 13.90it/s]\n","ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n","ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n","ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-123-35b062c319da>\", line 64, in <cell line: 50>\n","    l, summaries = net.loss(fmri, labels)\n","  File \"<ipython-input-122-c75622d3b635>\", line 358, in loss\n","    nelbo, kl, rec = self.negative_iwae_bound(fmri, label)\n","  File \"<ipython-input-122-c75622d3b635>\", line 344, in negative_iwae_bound\n","    logits = self.decode(z, label)\n","  File \"<ipython-input-122-c75622d3b635>\", line 394, in decode\n","    res = nn.ReLU()(self.tp_conv4(res)) # batch, 1, 32, 32, 32\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 610, in forward\n","    return self._conv_forward(input, self.weight, self.bias)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 605, in _conv_forward\n","    return F.conv3d(\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-123-35b062c319da>\", line 64, in <cell line: 50>\n","    l, summaries = net.loss(fmri, labels)\n","  File \"<ipython-input-122-c75622d3b635>\", line 358, in loss\n","    nelbo, kl, rec = self.negative_iwae_bound(fmri, label)\n","  File \"<ipython-input-122-c75622d3b635>\", line 344, in negative_iwae_bound\n","    logits = self.decode(z, label)\n","  File \"<ipython-input-122-c75622d3b635>\", line 394, in decode\n","    res = nn.ReLU()(self.tp_conv4(res)) # batch, 1, 32, 32, 32\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 610, in forward\n","    return self._conv_forward(input, self.weight, self.bias)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 605, in _conv_forward\n","    return F.conv3d(\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n","    self.showtraceback(running_compiled_code=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-123-35b062c319da>\", line 64, in <cell line: 50>\n","    l, summaries = net.loss(fmri, labels)\n","  File \"<ipython-input-122-c75622d3b635>\", line 358, in loss\n","    nelbo, kl, rec = self.negative_iwae_bound(fmri, label)\n","  File \"<ipython-input-122-c75622d3b635>\", line 344, in negative_iwae_bound\n","    logits = self.decode(z, label)\n","  File \"<ipython-input-122-c75622d3b635>\", line 394, in decode\n","    res = nn.ReLU()(self.tp_conv4(res)) # batch, 1, 32, 32, 32\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 610, in forward\n","    return self._conv_forward(input, self.weight, self.bias)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 605, in _conv_forward\n","    return F.conv3d(\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n","    self.showtraceback(running_compiled_code=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n","    self.showtraceback()\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n","    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n"]}]},{"cell_type":"code","source":["len(samples_class_0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j5OhrketlGSI","executionInfo":{"status":"ok","timestamp":1701749494135,"user_tz":480,"elapsed":717,"user":{"displayName":"Jiaqi Wu","userId":"00803091932349494936"}},"outputId":"f9781d02-4179-41af-8ca7-fd7e30af1830"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["80"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["plt.plot(train_losses)\n","plt.title(\"Training loss\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":470},"id":"3vrH1WvILI-f","executionInfo":{"status":"ok","timestamp":1701749601962,"user_tz":480,"elapsed":815,"user":{"displayName":"Jiaqi Wu","userId":"00803091932349494936"}},"outputId":"6df38827-1123-489d-d346-38407b11089a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 1.0, 'Training loss')"]},"metadata":{},"execution_count":36},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"YmcsDE9RqILC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uOKEQS-RQfHp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3D VAE-GAN Model"],"metadata":{"id":"AiBMtCW8Qfmn"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import os\n","from torch import nn\n","from torch import optim\n","from torch.nn import functional as F\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, channel=512,out_class=1):\n","        super(Discriminator, self).__init__()\n","\n","        self.channel = channel\n","        n_class = out_class\n","\n","        self.conv1 = nn.Conv3d(1, channel//8, kernel_size=4, stride=2, padding=1)\n","        self.conv2 = nn.Conv3d(channel//8, channel//4, kernel_size=4, stride=2, padding=1)\n","        self.bn2 = nn.BatchNorm3d(channel//4)\n","        self.conv3 = nn.Conv3d(channel//4, channel//2, kernel_size=4, stride=2, padding=1)\n","        self.bn3 = nn.BatchNorm3d(channel//2)\n","        self.conv4 = nn.Conv3d(channel//2, channel, kernel_size=4, stride=2, padding=1)\n","        self.bn4 = nn.BatchNorm3d(channel)\n","        self.conv5 = nn.Conv3d(channel, n_class, kernel_size=4, stride=1, padding=0)\n","\n","\n","    def forward(self, x):\n","        batch_size = x.size()[0]\n","        h1 = F.leaky_relu(self.conv1(x), negative_slope=0.2)\n","        h2 = F.leaky_relu(self.bn2(self.conv2(h1)), negative_slope=0.2)\n","        h3 = F.leaky_relu(self.bn3(self.conv3(h2)), negative_slope=0.2)\n","        h4 = F.leaky_relu(self.bn4(self.conv4(h3)), negative_slope=0.2)\n","        h5 = self.conv5(h4)\n","        output = F.sigmoid(h5.view(h5.size()[0],-1))\n","        return output\n","\n","class Encoder(nn.Module):\n","    def __init__(self, channel=512,out_class=1):\n","        super(Encoder, self).__init__()\n","\n","        self.channel = channel\n","        n_class = out_class\n","\n","        self.conv1 = nn.Conv3d(1, channel//8, kernel_size=4, stride=2, padding=1)\n","        self.conv2 = nn.Conv3d(channel//8, channel//4, kernel_size=4, stride=2, padding=1)\n","        self.bn2 = nn.BatchNorm3d(channel//4)\n","        self.conv3 = nn.Conv3d(channel//4, channel//2, kernel_size=4, stride=2, padding=1)\n","        self.bn3 = nn.BatchNorm3d(channel//2)\n","        self.conv4 = nn.Conv3d(channel//2, channel, kernel_size=4, stride=2, padding=1)\n","        self.bn4 = nn.BatchNorm3d(channel)\n","\n","        self.mean = nn.Sequential(\n","            nn.Linear(32768, 2048),\n","            nn.BatchNorm1d(2048),\n","            nn.ReLU(),\n","            nn.Linear(2048, 1000))\n","        self.logvar = nn.Sequential(\n","            nn.Linear(32768, 2048),\n","            nn.BatchNorm1d(2048),\n","            nn.ReLU(),\n","            nn.Linear(2048, 1000))\n","\n","    def forward(self, x, _return_activations=False):\n","        batch_size = x.size()[0]\n","        h1 = F.leaky_relu(self.conv1(x), negative_slope=0.2)\n","        h2 = F.leaky_relu(self.bn2(self.conv2(h1)), negative_slope=0.2)\n","        h3 = F.leaky_relu(self.bn3(self.conv3(h2)), negative_slope=0.2)\n","        h4 = F.leaky_relu(self.bn4(self.conv4(h3)), negative_slope=0.2)\n","\n","        mean = self.mean(h4.view(batch_size,-1))\n","        logvar = self.logvar(h4.view(batch_size,-1))\n","\n","        std = logvar.mul(0.5).exp_()\n","        reparametrized_noise = Variable(torch.randn((batch_size, 1000))).cuda()\n","        reparametrized_noise = mean + std * reparametrized_noise\n","        return mean,logvar ,reparametrized_noise\n","\n","class Generator(nn.Module):\n","    def __init__(self, noise:int=100, channel:int=64):\n","        super(Generator, self).__init__()\n","        _c = channel\n","\n","        self.noise = noise\n","        self.fc = nn.Linear(1000,512*4*4*4)\n","        self.bn1 = nn.BatchNorm3d(_c*8)\n","\n","        self.tp_conv2 = nn.Conv3d(_c*8, _c*4, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm3d(_c*4)\n","\n","        self.tp_conv3 = nn.Conv3d(_c*4, _c*2, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn3 = nn.BatchNorm3d(_c*2)\n","\n","        self.tp_conv4 = nn.Conv3d(_c*2, _c, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn4 = nn.BatchNorm3d(_c)\n","\n","        self.tp_conv5 = nn.Conv3d(_c, 1, kernel_size=3, stride=1, padding=1, bias=False)\n","\n","    def forward(self, noise):\n","        noise = noise.view(-1, 1000)\n","        h = self.fc(noise)\n","        h = h.view(-1,512,4,4,4)\n","        h = F.relu(self.bn1(h))\n","\n","        h = F.upsample(h,scale_factor = 2)\n","        h = self.tp_conv2(h)\n","        h = F.relu(self.bn2(h))\n","\n","        h = F.upsample(h,scale_factor = 2)\n","        h = self.tp_conv3(h)\n","        h = F.relu(self.bn3(h))\n","\n","        h = F.upsample(h,scale_factor = 2)\n","        h = self.tp_conv4(h)\n","        h = F.relu(self.bn4(h))\n","\n","        h = F.upsample(h,scale_factor = 2)\n","        h = self.tp_conv5(h)\n","\n","        h = F.tanh(h)\n","\n","        return h"],"metadata":{"id":"LwCBqmtoQiHC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## GAN Model Training"],"metadata":{"id":"mBUIjz-sQvZ2"}},{"cell_type":"code","source":["# resize fmri\n","train_f_gan = []\n","for f in train_f:\n","  f = resize_volume(f, 64, 64, 64)\n","  train_f_gan.append(f)\n","\n","train_f_gan = np.stack(np.array(train_f_gan), axis=0)"],"metadata":{"id":"J54xmkR1TRyU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import os\n","import time\n","from torch import nn\n","from torch import optim\n","from torch.nn import functional as F\n","from torch import autograd\n","from torch.autograd import Variable\n","import nibabel as nib\n","from torch.utils.data.dataset import Dataset\n","from nilearn import plotting\n","from pathlib import Path\n","from dataset import MRIDataset\n","from tensorboardX import SummaryWriter\n","import argparse\n","import matplotlib.pyplot as plt\n","torch.autograd.set_detect_anomaly(True)\n","\n","\n","BATCH_SIZE=4\n","gpu = True\n","workers = 1\n","LAMBDA= 10\n","_eps = 1e-15\n","\n","Use_BRATS = False\n","Use_ATLAS = False\n","\n","gamma = 20\n","beta = 10\n","\n","#setting latent variable sizes\n","latent_dim = 1000\n","lr_g = 0.0001\n","lr_e = 0.0001\n","lr_d = 0.0001\n","\n","# Need to resize to (64, 64, 64)\n","dataset = torch.utils.data.TensorDataset(train_f_gan)\n","\n","def inf_train_gen(data_loader):\n","    while True:\n","        for _,images in enumerate(data_loader):\n","            assert images.shape[1:] == (1,144,192,144)\n","            yield images\n","\n","def train(args):\n","    print(\"Training VAE GAN hyperparameters: \")\n","    print('lr_g: {:<8.3}'.format(lr_g),\n","          'lr_e: {:<8.3}'.format(lr_e),\n","          'lr_d: {:<8.3}'.format(lr_d),\n","          'g_iter: {}'.format(g_iter),\n","          'latent_dim: {}'.format(latent_dim),\n","          'batch_size: {}'.format(batch_size)\n","        )\n","    train_loader = torch.utils.data.DataLoader(train_dataloader,batch_size=args.batch_size,\n","                                          shuffle=True,num_workers=workers)\n","    G = Generator(noise = latent_dim)\n","    D = Discriminator()\n","    E = Encoder()\n","\n","    G.cuda()\n","    D.cuda()\n","    E.cuda()\n","\n","\n","    g_optimizer = optim.Adam(G.parameters(), lr=lr_g)\n","    d_optimizer = optim.Adam(D.parameters(), lr=lr_d)\n","    e_optimizer = optim.Adam(E.parameters(), lr=lr_e)\n","\n","    real_y = Variable(torch.ones((args.batch_size, 1)).cuda())\n","    fake_y = Variable(torch.zeros((args.batch_size, 1)).cuda())\n","\n","    criterion_bce = nn.BCELoss()\n","    criterion_l1 = nn.L1Loss()\n","    criterion_mse = nn.MSELoss()\n","\n","    gen_load = inf_train_gen(train_loader)\n","\n","    for iteration in range(args.continue_iter, args.iter):\n","        # print(\"....Iterating....\")\n","        for step, real_images in enumerate(train_loader):\n","            _batch_size = real_images.size(0)\n","            real_images = Variable(real_images,requires_grad=False).cuda()\n","            z_rand = Variable(torch.randn((_batch_size, latent_dim)),requires_grad=False).cuda()\n","            mean,logvar,code = E(real_images)\n","            x_rec = G(code)\n","            assert x_rec.shape == real_images.shape\n","            x_rand = G(z_rand)\n","            ###############################################\n","            # Train D\n","            ###############################################\n","            d_optimizer.zero_grad()\n","\n","            d_real_loss = criterion_bce(D(real_images),real_y[:_batch_size])\n","            d_recon_loss = criterion_bce(D(x_rec), fake_y[:_batch_size])\n","            d_fake_loss = criterion_bce(D(x_rand), fake_y[:_batch_size])\n","\n","            dis_loss = d_recon_loss+d_real_loss + d_fake_loss\n","            dis_loss.backward(retain_graph=True)\n","\n","            d_optimizer.step()\n","\n","            ###############################################\n","            # Train G\n","            ###############################################\n","            g_optimizer.zero_grad()\n","            output = D(real_images)\n","            d_real_loss = criterion_bce(output,real_y[:_batch_size])\n","            output = D(x_rec)\n","            d_recon_loss = criterion_bce(output,fake_y[:_batch_size])\n","            output = D(x_rand)\n","            d_fake_loss = criterion_bce(output,fake_y[:_batch_size])\n","\n","            d_img_loss = d_real_loss + d_recon_loss+ d_fake_loss\n","            gen_img_loss = -d_img_loss\n","\n","            rec_loss = ((x_rec - real_images)**2).mean()\n","\n","            err_dec = gamma* rec_loss + gen_img_loss\n","\n","            err_dec.backward(retain_graph=True)\n","            g_optimizer.step()\n","\n","            ###############################################\n","            # Train E\n","            ###############################################\n","            prior_loss = 1+logvar-mean.pow(2) - logvar.exp()\n","            prior_loss = (-0.5*torch.sum(prior_loss))/torch.numel(mean.data)\n","            rec_loss = ((G(code) - real_images)**2).mean()\n","            err_enc = prior_loss + beta*rec_loss # TODO: ?????\n","\n","            e_optimizer.zero_grad()\n","            err_enc.backward()\n","            e_optimizer.step()\n","            # TODO: moved g_optimizer here according to\n","            # https://discuss.pytorch.org/t/runtimeerror-one-of-the-variables-needed-for-gradient-computation-has-been-modified-by-an-inplace-operation-code-worked-in-pytorch-1-2-but-not-in-1-5-after-updating/87327/4\n","            # g_optimizer.step()\n","        # print(\"Finished one iteration\")\n","\n","        if (iteration+1) % 5 == 0:\n","            end = time.time()\n","            duration = int(end - start)\n","            print('[{}/{}]'.format(iteration,MAX_ITER),\n","                'D: {:<8.3}'.format(dis_loss.item()),\n","                'En: {:<8.3}'.format(err_enc.item()),\n","                'De: {:<8.3}'.format(err_dec.item()),\n","                )\n"],"metadata":{"id":"ic4jwR3zQtck"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train()"],"metadata":{"id":"o6Ity9IURAHH"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"V100","machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}